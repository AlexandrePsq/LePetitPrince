{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we compare 4 different NLP models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose:\n",
    " - GloVe as a baseline model\n",
    " - LSTM \n",
    " - GPT2 (as a decoder transformer model)\n",
    " - BERT (as an encoder transformer model)\n",
    "\n",
    "For each model, we extracted weights from the model dynamic (or static) as a way of representing artificial brain activations resulting from natural language processing.\n",
    "These activations were shaped by the results of the section 'ActivationExtractionProtocol'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import umap\n",
    "import scipy\n",
    "import hdbscan\n",
    "import nistats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import manifold\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "from nilearn.image import load_img, mean_img, index_img, threshold_img, math_img, smooth_img, new_img_like\n",
    "from nilearn.input_data import NiftiMapsMasker, NiftiMasker, NiftiLabelsMasker, MultiNiftiMasker\n",
    "from nistats.second_level_model import SecondLevelModel\n",
    "from nistats.thresholding import map_threshold\n",
    "from nilearn import plotting\n",
    "from nilearn import datasets\n",
    "from scipy.stats import norm\n",
    "from nilearn.surface import vol_to_surf\n",
    "\n",
    "import utils \n",
    "import reporting\n",
    "from logger import Logger\n",
    "from linguistics_info import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = f\"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/\"\n",
    "OUTPUT_PATH = f\"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/maps/{language}\"\n",
    "INPUT_PATH = f\"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{language}\"\n",
    "FMRIDATA_PATH = f\"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/fMRI/{language}\"\n",
    "MASKER_PATH = f\"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/global_masker_95%_{language}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_maps, labels = reporting.load_atlas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainable ceiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting to look at the results of the comparison, we investigated how much signal could be explained putting aside noise from the activation and among subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_fast_srm_data = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/fastsrm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob(os.path.join(path_to_fast_srm_data, 'sub-*/R2_sub-*.npy')))\n",
    "data = [new_masker.inverse_transform(np.load(file_)) for file_ in files]\n",
    "img = mean_img(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(img, colorbar=True, display_mode='lzry', plot_abs=False, title='Predictable R2 value for each voxel with FastSRM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed the explained variance by mean of a cross-validated R2 value for each voxel.\n",
    "Cross-validation was done over sessions and then over sampled test-set (26 sampled test-set of 5 subjects with replacement) from all subjects.\n",
    "We therefore have X session-cross-validated R2 brain maps.\n",
    "We average these maps and transform its values to Pearson coefficients by taking the square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_img = math_img('np.sqrt(img)', img=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(img, colorbar=True, display_mode='lzry', plot_abs=False, title='Predictable Pearson value for each voxel with FastSRM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of the ActivationExtractionProtocol section, we compare the following models:\n",
    "- Glove\n",
    "- LSTM (1 hidden layer - 300 units)\n",
    "- GPT-2 (small version - all hidden layers + PCA with 300 components - 20 sentences of pre-context - norm infinity normalization before the pipeline - norm infinity normalization before the ridge regression)\n",
    "- BERT (small-version - cased - all hidden layers + PCA with 300 components - 7 sentences of pre-context - norm infinity normalization before the ridge regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'glove_300_{}',\n",
    "    'LSTM_embedding-size_600_nhid_300_nlayers_1_dropout_02_wiki_kristina_english_{}_all-hidden-layers',\n",
    "    'gpt2_pre-20_1_norm-inf_norm-inf_{}_hidden-all-layers_pca_300',\n",
    "    'bert-base-cased_pre-7_1_post-0_norm-None_norm-inf_temporal-shifting-0_{}_hidden-all-layers_pca_300',\n",
    "]\n",
    "legend_names = ['GloVe', \n",
    "                'LSTM-E600-H300-L1', \n",
    "                'GPT2-scaled-Hpca-pre-20',\n",
    "                'BERT-Hpca-pre-7-post-0'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_comparison = reporting.prepare_data_for_anova(\n",
    "    model_names, \n",
    "    atlas_maps, \n",
    "    labels, \n",
    "    MASKER_PATH,\n",
    "    object_of_interest='Pearson_coeff', \n",
    "    language='english',\n",
    "    OUTPUT_PATH='/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/maps/english'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_folder = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/anovas/'\n",
    "check_folder(saving_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_comparison.to_csv(os.path.join(saving_path, 'anova_comparison.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Do the anova analysis on R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = reporting.get_model_data(model_names, language, OUTPUT_PATH)\n",
    "data_model_comparison = { key.replace('_{}', ''): data_full[key.replace('_{}', '')] for key in model_names }\n",
    "data_to_plot = reporting.get_data_per_roi(\n",
    "                                data_model_comparison, \n",
    "                                atlas_maps,\n",
    "                                labels,\n",
    "                                analysis=None, \n",
    "                                language='english', \n",
    "                                object_of_interest='Pearson_coeff',\n",
    "                                PROJECT_PATH='/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/'\n",
    "                                )\n",
    "mean = data_to_plot['mean']\n",
    "third_quartile = data_to_plot['third_quartile']\n",
    "maximum = data_to_plot['maximum']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clever_plot(third_quartile, labels, legend_names, save_folder=None, roi_filter=load_syntactic_roi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clever_plot(third_quartile, labels, legend_names, save_folder=None, roi_filter=load_language_roi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clever_plot(third_quartile, labels, legend_names, save_folder=None, roi_filter=load_interesting_rois())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clever_plot(third_quartile, labels, legend_names, save_folder=None, roi_filter=load_intriguing_rois())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting.vertical_plot(\n",
    "                third_quartile, \n",
    "                labels, \n",
    "                'Third_Quartile_Pearson-coeff_per_ROI',\n",
    "                save_folder=None, \n",
    "                object_of_interest='Pearson_coeff', \n",
    "                legend_names=legend_names, \n",
    "                syntactic_roi=load_syntactic_roi(), \n",
    "                language_roi=load_language_roi(), \n",
    "                figsize=(9,18), \n",
    "                count=False, \n",
    "                title=None, \n",
    "                ylabel='Regions of interest (ROI)', \n",
    "                xlabel='Pearson_coeff value', \n",
    "                model_name='Model_comparison'\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
