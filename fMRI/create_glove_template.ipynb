{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to generate templates for GloVe models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "from utils import check_folder, read_yaml, save_yaml, write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_main = \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/code/fMRI/main.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_dict = {'english': [57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n",
    "                    72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93,\n",
    "                    94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 108, 109, 110, 113, 114, 115],\n",
    "                'french':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "                          21, 22, 23, 24, 25, 26, 27, 29, 30\n",
    "                         ]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrf_list = [\n",
    "    'spm', # hrf model used in SPM\n",
    "    'spm + derivative', # SPM model plus its time derivative (2 regressors)\n",
    "    'spm + derivative + dispersion', # idem, plus dispersion derivative (3 regressors)\n",
    "    'glover', # this one corresponds to the Glover hrf\n",
    "    'glover + derivative', # the Glover hrf + time derivative (2 regressors)\n",
    "    'glover + derivative + dispersion' # idem + dispersion derivative\n",
    "]\n",
    "hrf = 'spm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'\n",
    "temporal_shifting = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = {\n",
    "  # Shared General parameters\n",
    "  'subject': None,\n",
    "  'parallel': False,\n",
    "  'cuda': True,\n",
    "  'seed': 1111,\n",
    "  'language': None,\n",
    "  'path_to_root': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/\",\n",
    "  'path_to_fmridata': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/fMRI\",\n",
    "  'output': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/maps/\"  ,\n",
    "  'input': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/\" ,\n",
    "  'detrend': True, \n",
    "  'standardize': True, \n",
    "  'high_pass': None, \n",
    "  'low_pass': None, \n",
    "  'mask_strategy': 'background', \n",
    "  #'dtype': 'float32', \n",
    "  'memory_level': 0, \n",
    "  'smoothing_fwhm': None , \n",
    "  'verbose': 0, \n",
    "    \n",
    "  # Shared Splitter parameters\n",
    "  'nb_runs': 9,\n",
    "  'nb_runs_test': 1,\n",
    "\n",
    "  # Shared Compression parameters\n",
    "\n",
    "\n",
    "  # Shared Transformation parameters (includes the making of regressor and scaling)\n",
    "  'tr': 2.,\n",
    "  'scaling_mean': True,\n",
    "  'scaling_var': True,\n",
    "  'scaling_axis': None,\n",
    "  'hrf': None,\n",
    "  'offset_path': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/onsets-offsets/\",\n",
    "  'duration_path': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/\",\n",
    "  'temporal_shifting': 0,\n",
    "\n",
    "  # Shared Estimator model parameters\n",
    "  'base': 10.0,\n",
    "  'voxel_wise': True,\n",
    "  'alpha_percentile': 99.9,\n",
    "  'alpha': None,\n",
    "  'alpha_min_log_scale': 2,\n",
    "  'alpha_max_log_scale': 5,\n",
    "  'nb_alphas': 10,\n",
    "  'optimizing_criteria': 'R2',\n",
    "  'estimator_model': 'Ridge()',\n",
    "\n",
    "  # Maps creation parameters\n",
    "  'atlas': 'cort-prob-2mm',\n",
    "  'masker_path': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/global_masker_english\",\n",
    "  'smoothed_masker_path': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/smoothed_global_masker_english\",\n",
    "\n",
    "\n",
    "  # Models\n",
    "  'models': None, \n",
    "  'model_name': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_commands(command_lines, path_to_sh):\n",
    "    for index, command in enumerate(command_lines):\n",
    "        write(path_to_sh[index], command)\n",
    "        queue = 'Nspin_long' # 'Nspin_bigM'\n",
    "        walltime = '99:00:00'\n",
    "        output_log = '/home/ap259944/logs/log_o_{}'.format(index)\n",
    "        error_log = '/home/ap259944/logs/log_e_{}'.format(index)\n",
    "        job_name = ''.join(os.path.basename(path_to_sh[index]).split('.')[:-1])\n",
    "        write(job_to_launch_path, f\"qsub -q {queue} -N {job_name} -l walltime={walltime} -o {output_log} -e {error_log} {path_to_sh[index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_template(\n",
    "    model_name, \n",
    "    embedding_size,\n",
    "    surname,\n",
    "    data_compression, \n",
    "    ncomponents,\n",
    "    offset_type,\n",
    "    duration_type,\n",
    "    shift_surprisal,\n",
    "    centering,\n",
    "    order,\n",
    "    scaling_type,\n",
    "    input_template='activations'):\n",
    "    \n",
    "    columns_to_retrieve = ['embedding-{}'.format(i) for i in range(1, embedding_size + 1)]\n",
    "    result = { \n",
    "        'model_name': model_name,\n",
    "        'columns_to_retrieve': str(columns_to_retrieve),\n",
    "        'surname': surname,\n",
    "        'data_compression': data_compression,\n",
    "        'ncomponents': ncomponents,\n",
    "        'offset_type': offset_type, # word / word+punctuation / ...,\n",
    "        'duration_type': duration_type,\n",
    "        'shift_surprisal': shift_surprisal,\n",
    "        'centering': centering,\n",
    "        'order': order,\n",
    "        'scaling_type': scaling_type,\n",
    "        'input_template': input_template # cls / sep / activations\n",
    "      }\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here starts the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_folder = \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/tmp_glove/templates/\"\n",
    "sh_folder = \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/tmp_glove/shell_commands/\"\n",
    "job_to_launch_path = \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/tmp_glove/jobs.txt\"\n",
    "check_folder(templates_folder)\n",
    "check_folder(sh_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['glove_embeddings_wiki'] \n",
    "embedding_size = [300] * 8\n",
    "data_compression = [None] * 8\n",
    "ncomponents = [None] * 8\n",
    "shift_surprisal = False\n",
    "centering = [True] * 8\n",
    "order = [None]\n",
    "scaling_type = ['normalize'] \n",
    "names =  ['glove_wiki_{}'.format(embedding_size[index]) for index in range(len(order))]# + ['glove_{}_standardize_centering'.format(embedding_size[-1])]\n",
    "command_lines = []\n",
    "path_to_sh = []\n",
    "scaling_axis = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glove_wiki_300']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "template['language'] = language\n",
    "template['temporal_shifting'] = temporal_shifting\n",
    "template['hrf'] = hrf\n",
    "template['scaling_axis'] = scaling_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, model_name in enumerate(model_names):\n",
    "    for subject in subject_dict[language]:\n",
    "        template['subject'] = subject\n",
    "        \n",
    "        # hidden layers comparison\n",
    "        model = get_glove_template(\n",
    "                            model_name=model_name, \n",
    "                            embedding_size=embedding_size[index],\n",
    "                            surname=names[index],\n",
    "                            data_compression=data_compression[index], \n",
    "                            ncomponents=ncomponents[index],\n",
    "                            offset_type=\"word+punctuation\",\n",
    "                            duration_type=None,\n",
    "                            shift_surprisal=False,\n",
    "                            centering=centering[index],\n",
    "                            order=order[index],\n",
    "                            scaling_type=scaling_type[index],\n",
    "                            input_template='activations')\n",
    "\n",
    "        template['models'] = [model]\n",
    "        template['model_name'] = names[index] + '_{}'.format(subject)\n",
    "        yaml_path = os.path.join(templates_folder, names[index] + '_{}.yml'.format(subject))\n",
    "\n",
    "        save_yaml(template, yaml_path)\n",
    "        command_lines.append(\"python {} --yaml_file {}\".format(path_to_main, yaml_path))\n",
    "        path_to_sh.append(os.path.join(sh_folder, names[index] + '_{}.sh'.format(subject)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_commands(command_lines, path_to_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 115,\n",
       " 'parallel': False,\n",
       " 'cuda': True,\n",
       " 'seed': 1111,\n",
       " 'language': 'english',\n",
       " 'path_to_root': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/',\n",
       " 'path_to_fmridata': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/fMRI',\n",
       " 'output': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/maps/',\n",
       " 'input': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/',\n",
       " 'detrend': True,\n",
       " 'standardize': True,\n",
       " 'high_pass': None,\n",
       " 'low_pass': None,\n",
       " 'mask_strategy': 'background',\n",
       " 'memory_level': 0,\n",
       " 'smoothing_fwhm': None,\n",
       " 'verbose': 0,\n",
       " 'nb_runs': 9,\n",
       " 'nb_runs_test': 1,\n",
       " 'tr': 2.0,\n",
       " 'scaling_mean': True,\n",
       " 'scaling_var': True,\n",
       " 'scaling_axis': 1,\n",
       " 'hrf': 'spm',\n",
       " 'offset_path': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/onsets-offsets/',\n",
       " 'duration_path': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/',\n",
       " 'temporal_shifting': 0,\n",
       " 'base': 10.0,\n",
       " 'voxel_wise': True,\n",
       " 'alpha_percentile': 99.9,\n",
       " 'alpha': None,\n",
       " 'alpha_min_log_scale': 2,\n",
       " 'alpha_max_log_scale': 5,\n",
       " 'nb_alphas': 10,\n",
       " 'optimizing_criteria': 'R2',\n",
       " 'estimator_model': 'Ridge()',\n",
       " 'atlas': 'cort-prob-2mm',\n",
       " 'masker_path': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/global_masker_english',\n",
       " 'smoothed_masker_path': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/smoothed_global_masker_english',\n",
       " 'models': [{'model_name': 'glove_embeddings_wiki',\n",
       "   'columns_to_retrieve': \"['embedding-1', 'embedding-2', 'embedding-3', 'embedding-4', 'embedding-5', 'embedding-6', 'embedding-7', 'embedding-8', 'embedding-9', 'embedding-10', 'embedding-11', 'embedding-12', 'embedding-13', 'embedding-14', 'embedding-15', 'embedding-16', 'embedding-17', 'embedding-18', 'embedding-19', 'embedding-20', 'embedding-21', 'embedding-22', 'embedding-23', 'embedding-24', 'embedding-25', 'embedding-26', 'embedding-27', 'embedding-28', 'embedding-29', 'embedding-30', 'embedding-31', 'embedding-32', 'embedding-33', 'embedding-34', 'embedding-35', 'embedding-36', 'embedding-37', 'embedding-38', 'embedding-39', 'embedding-40', 'embedding-41', 'embedding-42', 'embedding-43', 'embedding-44', 'embedding-45', 'embedding-46', 'embedding-47', 'embedding-48', 'embedding-49', 'embedding-50', 'embedding-51', 'embedding-52', 'embedding-53', 'embedding-54', 'embedding-55', 'embedding-56', 'embedding-57', 'embedding-58', 'embedding-59', 'embedding-60', 'embedding-61', 'embedding-62', 'embedding-63', 'embedding-64', 'embedding-65', 'embedding-66', 'embedding-67', 'embedding-68', 'embedding-69', 'embedding-70', 'embedding-71', 'embedding-72', 'embedding-73', 'embedding-74', 'embedding-75', 'embedding-76', 'embedding-77', 'embedding-78', 'embedding-79', 'embedding-80', 'embedding-81', 'embedding-82', 'embedding-83', 'embedding-84', 'embedding-85', 'embedding-86', 'embedding-87', 'embedding-88', 'embedding-89', 'embedding-90', 'embedding-91', 'embedding-92', 'embedding-93', 'embedding-94', 'embedding-95', 'embedding-96', 'embedding-97', 'embedding-98', 'embedding-99', 'embedding-100', 'embedding-101', 'embedding-102', 'embedding-103', 'embedding-104', 'embedding-105', 'embedding-106', 'embedding-107', 'embedding-108', 'embedding-109', 'embedding-110', 'embedding-111', 'embedding-112', 'embedding-113', 'embedding-114', 'embedding-115', 'embedding-116', 'embedding-117', 'embedding-118', 'embedding-119', 'embedding-120', 'embedding-121', 'embedding-122', 'embedding-123', 'embedding-124', 'embedding-125', 'embedding-126', 'embedding-127', 'embedding-128', 'embedding-129', 'embedding-130', 'embedding-131', 'embedding-132', 'embedding-133', 'embedding-134', 'embedding-135', 'embedding-136', 'embedding-137', 'embedding-138', 'embedding-139', 'embedding-140', 'embedding-141', 'embedding-142', 'embedding-143', 'embedding-144', 'embedding-145', 'embedding-146', 'embedding-147', 'embedding-148', 'embedding-149', 'embedding-150', 'embedding-151', 'embedding-152', 'embedding-153', 'embedding-154', 'embedding-155', 'embedding-156', 'embedding-157', 'embedding-158', 'embedding-159', 'embedding-160', 'embedding-161', 'embedding-162', 'embedding-163', 'embedding-164', 'embedding-165', 'embedding-166', 'embedding-167', 'embedding-168', 'embedding-169', 'embedding-170', 'embedding-171', 'embedding-172', 'embedding-173', 'embedding-174', 'embedding-175', 'embedding-176', 'embedding-177', 'embedding-178', 'embedding-179', 'embedding-180', 'embedding-181', 'embedding-182', 'embedding-183', 'embedding-184', 'embedding-185', 'embedding-186', 'embedding-187', 'embedding-188', 'embedding-189', 'embedding-190', 'embedding-191', 'embedding-192', 'embedding-193', 'embedding-194', 'embedding-195', 'embedding-196', 'embedding-197', 'embedding-198', 'embedding-199', 'embedding-200', 'embedding-201', 'embedding-202', 'embedding-203', 'embedding-204', 'embedding-205', 'embedding-206', 'embedding-207', 'embedding-208', 'embedding-209', 'embedding-210', 'embedding-211', 'embedding-212', 'embedding-213', 'embedding-214', 'embedding-215', 'embedding-216', 'embedding-217', 'embedding-218', 'embedding-219', 'embedding-220', 'embedding-221', 'embedding-222', 'embedding-223', 'embedding-224', 'embedding-225', 'embedding-226', 'embedding-227', 'embedding-228', 'embedding-229', 'embedding-230', 'embedding-231', 'embedding-232', 'embedding-233', 'embedding-234', 'embedding-235', 'embedding-236', 'embedding-237', 'embedding-238', 'embedding-239', 'embedding-240', 'embedding-241', 'embedding-242', 'embedding-243', 'embedding-244', 'embedding-245', 'embedding-246', 'embedding-247', 'embedding-248', 'embedding-249', 'embedding-250', 'embedding-251', 'embedding-252', 'embedding-253', 'embedding-254', 'embedding-255', 'embedding-256', 'embedding-257', 'embedding-258', 'embedding-259', 'embedding-260', 'embedding-261', 'embedding-262', 'embedding-263', 'embedding-264', 'embedding-265', 'embedding-266', 'embedding-267', 'embedding-268', 'embedding-269', 'embedding-270', 'embedding-271', 'embedding-272', 'embedding-273', 'embedding-274', 'embedding-275', 'embedding-276', 'embedding-277', 'embedding-278', 'embedding-279', 'embedding-280', 'embedding-281', 'embedding-282', 'embedding-283', 'embedding-284', 'embedding-285', 'embedding-286', 'embedding-287', 'embedding-288', 'embedding-289', 'embedding-290', 'embedding-291', 'embedding-292', 'embedding-293', 'embedding-294', 'embedding-295', 'embedding-296', 'embedding-297', 'embedding-298', 'embedding-299', 'embedding-300']\",\n",
       "   'surname': 'glove_wiki_300',\n",
       "   'data_compression': None,\n",
       "   'ncomponents': None,\n",
       "   'offset_type': 'word+punctuation',\n",
       "   'duration_type': None,\n",
       "   'shift_surprisal': False,\n",
       "   'centering': True,\n",
       "   'order': None,\n",
       "   'scaling_type': 'normalize',\n",
       "   'input_template': 'activations'}],\n",
       " 'model_name': 'glove_wiki_300_115'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
