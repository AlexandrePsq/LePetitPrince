{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to generate templates for Transformer-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from utils import check_folder, read_yaml, save_yaml, write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_main = \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/code/fMRI/fast_main.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_dict = {'english': [57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n",
    "                    72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93,\n",
    "                    94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 108, 109, 110, 113, 114, 115],\n",
    "                'french':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "                          21, 22, 23, 24, 25, 26, 27, 29, 30\n",
    "                         ]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrf_list = [\n",
    "    'spm', # hrf model used in SPM\n",
    "    'spm + derivative', # SPM model plus its time derivative (2 regressors)\n",
    "    'spm + derivative + dispersion', # idem, plus dispersion derivative (3 regressors)\n",
    "    'glover', # this one corresponds to the Glover hrf\n",
    "    'glover + derivative', # the Glover hrf + time derivative (2 regressors)\n",
    "    'glover + derivative + dispersion' # idem + dispersion derivative\n",
    "]\n",
    "hrf = 'spm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'\n",
    "temporal_shifting = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = {\n",
    "  # Shared General parameters\n",
    "  'subject': None,\n",
    "  'parallel': False,\n",
    "  'cuda': True,\n",
    "  'seed': 1111,\n",
    "  'language': None,\n",
    "  'path_to_root': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/\",\n",
    "  'path_to_fmridata': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/fMRI\",\n",
    "  'output': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/maps/\"  ,\n",
    "  'input': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/\" ,\n",
    "  'detrend': True, \n",
    "  'standardize': True, \n",
    "  'high_pass': None, \n",
    "  'low_pass': None, \n",
    "  'mask_strategy': 'background', \n",
    "  #'dtype': 'float32', \n",
    "  'memory_level': 0, \n",
    "  'smoothing_fwhm': None , \n",
    "  'verbose': 0, \n",
    "\n",
    "\n",
    "  # Shared Splitter parameters\n",
    "  'nb_runs': 9,\n",
    "  'nb_runs_test': 1,\n",
    "\n",
    "  # Shared Compression parameters\n",
    "  'manifold_method': None,\n",
    "  'manifold_args': {'n_neighbors':4, 'random_state':1111, 'min_dist':0.0, 'metric':'cosine'},\n",
    "\n",
    "  # Shared Transformation parameters (includes the making of regressor and scaling)\n",
    "  'tr': 2.,\n",
    "  'scaling_mean': True,\n",
    "  'scaling_var': True,\n",
    "  'scaling_axis': 0,\n",
    "  'hrf': None,\n",
    "  'offset_path': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/onsets-offsets/\",\n",
    "  'duration_path': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/\",\n",
    "  'temporal_shifting': 0,\n",
    "  'oversampling': 10,\n",
    "  'add_noise_to_constant': True,\n",
    "\n",
    "  # Shared Estimator model parameters\n",
    "  'base': 10.0,\n",
    "  'voxel_wise': True,\n",
    "  'alpha_percentile': 99.9,\n",
    "  'alpha': 100,\n",
    "  'alpha_min_log_scale': 2,\n",
    "  'alpha_max_log_scale': 3,\n",
    "  'nb_alphas': 1,\n",
    "  'optimizing_criteria': 'R2',\n",
    "  'estimator_model': 'Ridge()',\n",
    "  'save_all_weights': False, \n",
    "\n",
    "  # Maps creation parameters\n",
    "  'atlas': 'cort-prob-2mm',\n",
    "  'masker_path': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/ROI_masks/global_masker_english\",\n",
    "  'smoothed_masker_path': \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/ROI_masks/smoothed_global_masker_english\",\n",
    "\n",
    "\n",
    "  # Models\n",
    "  'models': None, \n",
    "  'model_name': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_commands(command_lines, path_to_sh, job_to_launch_path, queue='Nspin_bigM'):\n",
    "    for index, command in enumerate(command_lines):\n",
    "        write(os.path.join('/', job_to_launch_path.split('/')[1], '/'.join(path_to_sh[index].split('/')[2:])), command)\n",
    "        walltime = '99:00:00'\n",
    "        output_log = '/home/ap263679/logs/log_o_{}'.format(index)\n",
    "        error_log = '/home/ap263679/logs/log_e_{}'.format(index)\n",
    "        job_name = os.path.basename(path_to_sh[index]).split('.')[0]\n",
    "        write(job_to_launch_path, f\"qsub -q {queue} -N {job_name} -l ncpus=6 -l walltime={walltime} -o {output_log} -e {error_log} {path_to_sh[index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BF_template(\n",
    "    model_name, \n",
    "    column_names,\n",
    "    surname,\n",
    "    data_compression, \n",
    "    ncomponents,\n",
    "    offset_type,\n",
    "    duration_type,\n",
    "    shift_surprisal,\n",
    "    centering,\n",
    "    order,\n",
    "    scaling_type,\n",
    "    input_template='activations'):\n",
    "    \n",
    "    columns_to_retrieve = column_names\n",
    "    result = { \n",
    "        'model_name': model_name,\n",
    "        'columns_to_retrieve': str(columns_to_retrieve),\n",
    "        'surname': surname,\n",
    "        'data_compression': data_compression,\n",
    "        'ncomponents': ncomponents,\n",
    "        'offset_type': offset_type, # word / word+punctuation / ...,\n",
    "        'duration_type': duration_type,\n",
    "        'shift_surprisal': shift_surprisal,\n",
    "        'input_template': input_template, # activations\n",
    "        'centering': centering,\n",
    "        'order': order,\n",
    "        'scaling_type': scaling_type,\n",
    "      }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_template(\n",
    "    model_name, \n",
    "    layers, \n",
    "    hidden_states, \n",
    "    attention_heads, \n",
    "    heads,\n",
    "    surname,\n",
    "    data_compression, \n",
    "    ncomponents,\n",
    "    nb_hidden_states=768,\n",
    "    offset_type='word+punctuation',\n",
    "    duration_type=None,\n",
    "    centering=False,\n",
    "    shift_surprisal=False,\n",
    "    scaling_type=None,\n",
    "    order=None,\n",
    "    input_template='activations'):\n",
    "    \n",
    "    columns_to_retrieve = []\n",
    "    if hidden_states:\n",
    "        columns_to_retrieve = ['hidden_state-layer-{}-{}'.format(layer, i) for layer in layers for i in range(1, nb_hidden_states + 1)]\n",
    "    if attention_heads:\n",
    "        columns_to_retrieve += ['attention-layer-{}-head-{}-{}'.format(layer, head, i) for layer in layers for head in heads for i in range(1, 65)]\n",
    "    result = { \n",
    "        'model_name': model_name,\n",
    "        'columns_to_retrieve': str(columns_to_retrieve),\n",
    "        'surname': surname,\n",
    "        'data_compression': data_compression,\n",
    "        'ncomponents': ncomponents,\n",
    "        'offset_type': offset_type, # word / word+punctuation / ...,\n",
    "        'duration_type': duration_type,\n",
    "        'shift_surprisal': shift_surprisal,\n",
    "        'centering': centering,\n",
    "        'order': order,\n",
    "        'scaling_type': scaling_type,\n",
    "        'input_template': input_template # cls / sep / activations\n",
    "      }\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we start the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_folder = \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/tmp_bert_units_768_8/templates/\"\n",
    "sh_folder = \"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/tmp_bert_units_768_8/shell_commands/\"\n",
    "job_to_launch_path = \"/Volumes/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/tmp_bert_units_768_8/jobs.txt\"\n",
    "check_folder(os.path.join('/', job_to_launch_path.split('/')[1], '/'.join(templates_folder.split('/')[2:])))\n",
    "check_folder(os.path.join('/', job_to_launch_path.split('/')[1], '/'.join(sh_folder.split('/')[2:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_template_folder(\n",
    "    templates_folder,\n",
    "    sh_folder,\n",
    "    job_to_launch_path,\n",
    "    model_names, \n",
    "    language, \n",
    "    template, \n",
    "    hidden_layer_list,\n",
    "    attention_layer_list,\n",
    "    attention_layer_head_list,\n",
    "    nb_hidden_states,\n",
    "    centering,\n",
    "    order,\n",
    "    scaling_type,\n",
    "    input_template,\n",
    "    data_compression,\n",
    "    ncomponents,\n",
    "    temporal_shifting,\n",
    "    path_to_main=path_to_main,\n",
    "    extra=[],\n",
    "    extra_name=''\n",
    "):\n",
    "    command_lines = []\n",
    "    path_to_sh = []\n",
    "    \n",
    "    for index, model_name in enumerate(model_names):\n",
    "        for subject in subject_dict[language]:\n",
    "            template['subject'] = subject\n",
    "\n",
    "            # hidden layers comparison\n",
    "            for hidden_layers in hidden_layer_list:\n",
    "                model = get_model_template(model_name=model_name, \n",
    "                                           layers=hidden_layers, \n",
    "                                           hidden_states=True,\n",
    "                                           attention_heads=False, \n",
    "                                           heads=None, \n",
    "                                           nb_hidden_states=nb_hidden_states[index],\n",
    "                                           surname=\"{}_hidden-layer-{}\".format(model_name, hidden_layers),\n",
    "                                           data_compression=data_compression[index], \n",
    "                                           ncomponents=ncomponents[index],\n",
    "                                           offset_type=\"word+punctuation\", \n",
    "                                           duration_type=None, \n",
    "                                           centering=centering[index],\n",
    "                                           order=order[index],\n",
    "                                           shift_surprisal=False,\n",
    "                                           scaling_type=scaling_type[index],\n",
    "                                           input_template=input_template\n",
    "                                          )\n",
    "                template['models'] = [model] + extra\n",
    "                additional = '_{}_{}'.format(data_compression[index], ncomponents[index]) if data_compression[index] is not None else ''\n",
    "                #template['model_name'] = '{}_norm-{}_temporal-shifting-{}_{}_hidden-layer-{}'.format(model_name, order[index], temporal_shifting, subject, '-'.join([str(i) for i in hidden_layers])).replace('np.', '') + extra_name\n",
    "                #yaml_path = os.path.join(templates_folder, '{}_norm-{}_temporal-shifting-{}_{}_hidden-layer-{}{}.yml'.format(model_name,  order[index], temporal_shifting, subject, '-'.join([str(i) for i in hidden_layers]), extra_name)).replace('np.', '')\n",
    "                template['model_name'] = '{}_norm-{}_temporal-shifting-{}_{}_hidden-all-layers{}'.format(model_name, order[index], temporal_shifting, subject, additional).replace('np.', '') + extra_name\n",
    "                yaml_path = os.path.join(templates_folder, '{}_norm-{}_temporal-shifting-{}_{}_hidden-all-layers{}{}.yml'.format(model_name, order[index], temporal_shifting, subject, additional, extra_name)).replace('np.', '')\n",
    "\n",
    "                save_yaml(template, os.path.join('/', job_to_launch_path.split('/')[1], '/'.join(yaml_path.split('/')[2:])))\n",
    "                command_lines.append(\"python {} --yaml_file {}\".format(path_to_main, yaml_path))\n",
    "                #path_to_sh.append(os.path.join(sh_folder, '{}_norm-{}_temporal-shifting-{}_{}_hidden-layer-{}{}.sh'.format(model_name, order[index], temporal_shifting, subject, '-'.join([str(i) for i in hidden_layers]), extra_name).replace('np.', '')))\n",
    "                path_to_sh.append(os.path.join(sh_folder, '{}_norm-{}_temporal-shifting-{}_{}_hidden-all-layers{}{}.sh'.format(model_name, order[index], temporal_shifting, subject, additional, extra_name).replace('np.', '')))\n",
    "\n",
    "            # attention layers comparison\n",
    "            for attention_layers in attention_layer_list:\n",
    "                model = get_model_template(model_name=model_name, \n",
    "                                           layers=attention_layers, \n",
    "                                           hidden_states=False,\n",
    "                                           attention_heads=True, \n",
    "                                           heads=heads, \n",
    "                                           surname=\"{}_norm-{}_attention-layer-{}\".format(model_name, order[index], attention_layers),\n",
    "                                           data_compression=data_compression[index], \n",
    "                                           ncomponents=ncomponents[index],\n",
    "                                           offset_type=\"word+punctuation\", \n",
    "                                           duration_type=None, \n",
    "                                           centering=centering[index],\n",
    "                                           order=order[index],\n",
    "                                           shift_surprisal=False,\n",
    "                                           scaling_type=scaling_type[index],\n",
    "                                           input_template=input_template\n",
    "                                          )\n",
    "                template['models'] = [model] + extra\n",
    "                #additional = '_{}_{}'.format(data_compression[index], ncomponents[index]) if data_compression[index] is not None else ''\n",
    "                template['model_name'] = '{}_norm-{}_temporal-shifting-{}_{}_attention-layer-{}'.format(model_name, order[index], temporal_shifting, subject, attention_layers[0]).replace('np.', '') + extra_name\n",
    "                yaml_path = os.path.join(templates_folder, '{}_norm-{}_temporal-shifting-{}_{}_attention-layer-{}{}.yml'.format(model_name, order[index], temporal_shifting, subject, attention_layers[0], extra_name)).replace('np.', '')\n",
    "                save_yaml(template, os.path.join('/', job_to_launch_path.split('/')[1], '/'.join(yaml_path.split('/')[2:])))\n",
    "                command_lines.append(\"python {} --yaml_file {}\".format(path_to_main, yaml_path))\n",
    "                path_to_sh.append(os.path.join(sh_folder, '{}_norm-{}_temporal-shifting-{}_{}_attention-layer-{}{}.sh'.format(model_name, order[index], temporal_shifting, subject, attention_layers[0], extra_name).replace('np.', '')))\n",
    "\n",
    "            # specific attention heads comparison    \n",
    "            for (layer, head) in attention_layer_head_list:\n",
    "                model = get_model_template(model_name=model_name, \n",
    "                                           layers=[layer], \n",
    "                                           hidden_states=False,\n",
    "                                           attention_heads=True, \n",
    "                                           heads=[head], \n",
    "                                           surname=\"{}_norm-{}_attention-layer-{}-head-{}\".format(model_name, order[index], layer, head),\n",
    "                                           data_compression=None, \n",
    "                                           ncomponents=None,\n",
    "                                           offset_type=\"word+punctuation\", \n",
    "                                           duration_type=None, \n",
    "                                           centering=centering[index],\n",
    "                                           order=order[index],\n",
    "                                           shift_surprisal=False,\n",
    "                                           scaling_type=scaling_type[index],\n",
    "                                           input_template=input_template\n",
    "                                          )\n",
    "                template['models'] = [model] + extra\n",
    "                template['model_name'] = '{}_norm-{}_temporal-shifting-{}_{}_attention-layer-{}_head-{}'.format(model_name, order[index], temporal_shifting, subject, layer, head).replace('np.', '') + extra_name\n",
    "                yaml_path = os.path.join(templates_folder, '{}_norm-{}_temporal-shifting-{}_{}_attention-layer-{}_head-{}{}.yml'.format(model_name, order[index], temporal_shifting, subject, layer, head, extra_name)).replace('np.', '')\n",
    "                save_yaml(template, os.path.join('/', job_to_launch_path.split('/')[1], '/'.join(yaml_path.split('/')[2:])))\n",
    "                command_lines.append(\"python {} --yaml_file {}\".format(path_to_main, yaml_path))\n",
    "                path_to_sh.append(os.path.join(sh_folder, '{}_norm-{}_temporal-shifting-{}_{}_attention-layer-{}_head-{}{}.sh'.format(model_name, order[index], temporal_shifting, subject, layer, head, extra_name).replace('np.', '')))\n",
    "    return path_to_sh, command_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "\n",
    "#\"bert-base-uncased_L-2_H-128_A-2_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-2_H-256_A-4_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-2_H-512_A-8_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-2_H-768_A-12_pre-20_norm-2\",\n",
    "\n",
    "#\"bert-base-uncased_L-4_H-128_A-2_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-4_H-256_A-4_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-4_H-512_A-8_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-4_H-768_A-12_pre-20_norm-2\",\n",
    "#    \n",
    "#\"bert-base-uncased_L-6_H-128_A-2_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-6_H-256_A-4_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-6_H-512_A-8_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-6_H-768_A-12_pre-20_norm-2\",\n",
    "#    \n",
    "#\"bert-base-uncased_L-8_H-128_A-2_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-8_H-256_A-4_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-8_H-512_A-8_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-8_H-768_A-12_pre-20_norm-2\",\n",
    "#    \n",
    "#\"bert-base-uncased_L-10_H-128_A-2_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-10_H-256_A-4_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-10_H-512_A-8_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-10_H-768_A-12_pre-20_norm-2\",\n",
    "#    \n",
    "\"bert-base-uncased_L-12_H-128_A-2_pre-20_norm-2\",\n",
    "\"bert-base-uncased_L-12_H-256_A-4_pre-20_norm-2\",\n",
    "\"bert-base-uncased_L-12_H-512_A-8_pre-20_norm-2\",\n",
    "\"bert-base-uncased_L-12_H-768_A-12_pre-20_norm-2\",\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_names = ['bert-base-cased', 'gpt2_scaled', 'roberta-base']\n",
    "hidden_layer_list =  [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12]] # [[i] for i in range(13)] # \n",
    "attention_layer_list = [] # [[i] for i in range(1, 13)]\n",
    "heads = np.arange(1, 13)\n",
    "attention_layer_head_list = [] # list(itertools.product(np.arange(1, 13), np.arange(1, 13)))\n",
    "#[[7, 6], [4, 10], [8, 1], [8,2], [6,7], [8, 10], [8, 11], [9, 6]]\n",
    "command_lines = []\n",
    "data_compression = [None] * 60\n",
    "ncomponents = [None] * 60\n",
    "order = [None] * 60\n",
    "centering = ['True'] * 60\n",
    "scaling_type = [None] * 60\n",
    "input_template = 'activations'\n",
    "scaling_axis = 0\n",
    "temporal_shifting = 0\n",
    "nb_hidden_states = [128, 256, 512, 768] * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_model_names = ['rms_chris']\n",
    "BF_offset_types = [\"rms_chris\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = []\n",
    "for index, model_name in enumerate(BF_model_names):\n",
    "    extra.append(get_BF_template(model_name, \n",
    "                                    ['amplitude'],\n",
    "                                    model_name,\n",
    "                                    None, \n",
    "                                    None,\n",
    "                                    BF_offset_types[index],\n",
    "                                    None,\n",
    "                                    False,\n",
    "                                    True, \n",
    "                                    None, \n",
    "                                    None,\n",
    "                                    input_template='activations'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "template['scaling_axis'] = scaling_axis\n",
    "template['language'] = language\n",
    "template['temporal_shifting'] = temporal_shifting\n",
    "template['hrf'] = hrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sh, command_lines = fill_template_folder(\n",
    "                    templates_folder,\n",
    "                    sh_folder,\n",
    "                    job_to_launch_path,\n",
    "                    model_names, \n",
    "                    language, \n",
    "                    template, \n",
    "                    hidden_layer_list,\n",
    "                    attention_layer_list,\n",
    "                    attention_layer_head_list,\n",
    "                    nb_hidden_states,\n",
    "                    centering,\n",
    "                    order,\n",
    "                    scaling_type,\n",
    "                    input_template,\n",
    "                    data_compression,\n",
    "                    ncomponents,\n",
    "                    temporal_shifting,\n",
    "                    path_to_main=path_to_main,\n",
    "                    extra=[],\n",
    "                    extra_name=''\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_commands(command_lines, path_to_sh, job_to_launch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(command_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \n",
    "#\"bert-base-uncased_L-2_H-128_A-2_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-2_H-256_A-4_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-2_H-512_A-8_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-2_H-768_A-12_pre-20_norm-2\",\n",
    "\n",
    "#\"bert-base-uncased_L-4_H-128_A-2_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-4_H-256_A-4_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-4_H-512_A-8_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-4_H-768_A-12_pre-20_norm-2\",\n",
    "#    \n",
    "#\"bert-base-uncased_L-6_H-128_A-2_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-6_H-256_A-4_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-6_H-512_A-8_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-6_H-768_A-12_pre-20_norm-2\",\n",
    "#    \n",
    "#\"bert-base-uncased_L-8_H-128_A-2_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-8_H-256_A-4_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-8_H-512_A-8_pre-20_norm-2\",\n",
    "\"bert-base-uncased_L-8_H-768_A-12_pre-20_norm-2\",\n",
    "#    \n",
    "#\"bert-base-uncased_L-10_H-128_A-2_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-10_H-256_A-4_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-10_H-512_A-8_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-10_H-768_A-12_pre-20_norm-2\",\n",
    "#    \n",
    "#\"bert-base-uncased_L-12_H-128_A-2_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-12_H-256_A-4_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-12_H-512_A-8_pre-20_norm-2\",\n",
    "#\"bert-base-uncased_L-12_H-768_A-12_pre-20_norm-2\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_layers = 8\n",
    "hidden_layer_list = [[i for i in range(1, nb_layers + 1)]] # attention à commencer à 0 ou 1 !!!!!\n",
    "attention_layer_list = [] # [[i for i in range(1, 13)]]\n",
    "attention_layer_head_list = [] # np.arange(1, 13)\n",
    "command_lines = []\n",
    "data_compression = [None] * 65\n",
    "ncomponents = [0] * 65\n",
    "order = [None] * 65 #'np.inf'\n",
    "centering = ['True'] * 65\n",
    "#scaling_type = ['standardize'] * 8 + ['normalize'] * 40\n",
    "scaling_type = [None] * 65\n",
    "input_template = 'activations'\n",
    "scaling_axis = 0\n",
    "temporal_shifting = 0\n",
    "nb_hidden_states = [768] * 65\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_model_names = ['wordrate', 'rms', 'log_frequency']\n",
    "BF_offset_types = [\"word\", \"rms_0.01\", \"word\"] * len(model_names) # [\"word\", \"rms_0.01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = []\n",
    "for index, model_name in enumerate(BF_model_names):\n",
    "    extra.append(get_BF_template(model_name, \n",
    "                                    [model_name],\n",
    "                                    model_name,\n",
    "                                    None, \n",
    "                                    None,\n",
    "                                    BF_offset_types[index],\n",
    "                                    None,\n",
    "                                    False,\n",
    "                                    True, \n",
    "                                    'np.inf', \n",
    "                                    0,\n",
    "                                    input_template='activations'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for index, model_name in enumerate(model_names):\n",
    "#    additional = '_{}_{}'.format(data_compression[index], ncomponents[index]) if data_compression[index] is not None else ''\n",
    "#    print('{}_norm-{}_{}_hidden-all-layers{}'.format(model_name, order[index], '{}',additional).replace('np.', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "template['estimator_model'] = 'B2B_reg()'\n",
    "template['save_all_weights'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "template['scaling_axis'] = scaling_axis\n",
    "template['language'] = language\n",
    "template['temporal_shifting'] = temporal_shifting\n",
    "template['hrf'] = hrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_sh, command_lines = fill_template_folder(\n",
    "                    templates_folder,\n",
    "                    sh_folder,\n",
    "                    job_to_launch_path,\n",
    "                    model_names, \n",
    "                    language, \n",
    "                    template, \n",
    "                    hidden_layer_list,\n",
    "                    attention_layer_list,\n",
    "                    attention_layer_head_list,\n",
    "                    nb_hidden_states,\n",
    "                    centering,\n",
    "                    order,\n",
    "                    scaling_type,\n",
    "                    input_template,\n",
    "                    data_compression,\n",
    "                    ncomponents,\n",
    "                    temporal_shifting,\n",
    "                    path_to_main=path_to_main,\n",
    "                    extra=[],\n",
    "                    extra_name='_alpha-100'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_commands(command_lines, path_to_sh, job_to_launch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 115,\n",
       " 'parallel': False,\n",
       " 'cuda': True,\n",
       " 'seed': 1111,\n",
       " 'language': 'english',\n",
       " 'path_to_root': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/',\n",
       " 'path_to_fmridata': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/fMRI',\n",
       " 'output': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/maps/',\n",
       " 'input': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/',\n",
       " 'detrend': True,\n",
       " 'standardize': True,\n",
       " 'high_pass': None,\n",
       " 'low_pass': None,\n",
       " 'mask_strategy': 'background',\n",
       " 'memory_level': 0,\n",
       " 'smoothing_fwhm': None,\n",
       " 'verbose': 0,\n",
       " 'nb_runs': 9,\n",
       " 'nb_runs_test': 1,\n",
       " 'manifold_method': None,\n",
       " 'manifold_args': {'n_neighbors': 4,\n",
       "  'random_state': 1111,\n",
       "  'min_dist': 0.0,\n",
       "  'metric': 'cosine'},\n",
       " 'tr': 2.0,\n",
       " 'scaling_mean': True,\n",
       " 'scaling_var': True,\n",
       " 'scaling_axis': 0,\n",
       " 'hrf': 'spm',\n",
       " 'offset_path': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/onsets-offsets/',\n",
       " 'duration_path': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/',\n",
       " 'temporal_shifting': 0,\n",
       " 'oversampling': 10,\n",
       " 'add_noise_to_constant': True,\n",
       " 'base': 10.0,\n",
       " 'voxel_wise': True,\n",
       " 'alpha_percentile': 99.9,\n",
       " 'alpha': 100,\n",
       " 'alpha_min_log_scale': 2,\n",
       " 'alpha_max_log_scale': 3,\n",
       " 'nb_alphas': 1,\n",
       " 'optimizing_criteria': 'R2',\n",
       " 'estimator_model': 'Ridge()',\n",
       " 'save_all_weights': False,\n",
       " 'atlas': 'cort-prob-2mm',\n",
       " 'masker_path': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/ROI_masks/global_masker_english',\n",
       " 'smoothed_masker_path': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/ROI_masks/smoothed_global_masker_english',\n",
       " 'models': [{'model_name': 'bert-base-uncased_L-2_H-768_A-12_pre-20_norm-2',\n",
       "   'columns_to_retrieve': \"['hidden_state-layer-1-1', 'hidden_state-layer-1-2', 'hidden_state-layer-1-3', 'hidden_state-layer-1-4', 'hidden_state-layer-1-5', 'hidden_state-layer-1-6', 'hidden_state-layer-1-7', 'hidden_state-layer-1-8', 'hidden_state-layer-1-9', 'hidden_state-layer-1-10', 'hidden_state-layer-1-11', 'hidden_state-layer-1-12', 'hidden_state-layer-1-13', 'hidden_state-layer-1-14', 'hidden_state-layer-1-15', 'hidden_state-layer-1-16', 'hidden_state-layer-1-17', 'hidden_state-layer-1-18', 'hidden_state-layer-1-19', 'hidden_state-layer-1-20', 'hidden_state-layer-1-21', 'hidden_state-layer-1-22', 'hidden_state-layer-1-23', 'hidden_state-layer-1-24', 'hidden_state-layer-1-25', 'hidden_state-layer-1-26', 'hidden_state-layer-1-27', 'hidden_state-layer-1-28', 'hidden_state-layer-1-29', 'hidden_state-layer-1-30', 'hidden_state-layer-1-31', 'hidden_state-layer-1-32', 'hidden_state-layer-1-33', 'hidden_state-layer-1-34', 'hidden_state-layer-1-35', 'hidden_state-layer-1-36', 'hidden_state-layer-1-37', 'hidden_state-layer-1-38', 'hidden_state-layer-1-39', 'hidden_state-layer-1-40', 'hidden_state-layer-1-41', 'hidden_state-layer-1-42', 'hidden_state-layer-1-43', 'hidden_state-layer-1-44', 'hidden_state-layer-1-45', 'hidden_state-layer-1-46', 'hidden_state-layer-1-47', 'hidden_state-layer-1-48', 'hidden_state-layer-1-49', 'hidden_state-layer-1-50', 'hidden_state-layer-1-51', 'hidden_state-layer-1-52', 'hidden_state-layer-1-53', 'hidden_state-layer-1-54', 'hidden_state-layer-1-55', 'hidden_state-layer-1-56', 'hidden_state-layer-1-57', 'hidden_state-layer-1-58', 'hidden_state-layer-1-59', 'hidden_state-layer-1-60', 'hidden_state-layer-1-61', 'hidden_state-layer-1-62', 'hidden_state-layer-1-63', 'hidden_state-layer-1-64', 'hidden_state-layer-1-65', 'hidden_state-layer-1-66', 'hidden_state-layer-1-67', 'hidden_state-layer-1-68', 'hidden_state-layer-1-69', 'hidden_state-layer-1-70', 'hidden_state-layer-1-71', 'hidden_state-layer-1-72', 'hidden_state-layer-1-73', 'hidden_state-layer-1-74', 'hidden_state-layer-1-75', 'hidden_state-layer-1-76', 'hidden_state-layer-1-77', 'hidden_state-layer-1-78', 'hidden_state-layer-1-79', 'hidden_state-layer-1-80', 'hidden_state-layer-1-81', 'hidden_state-layer-1-82', 'hidden_state-layer-1-83', 'hidden_state-layer-1-84', 'hidden_state-layer-1-85', 'hidden_state-layer-1-86', 'hidden_state-layer-1-87', 'hidden_state-layer-1-88', 'hidden_state-layer-1-89', 'hidden_state-layer-1-90', 'hidden_state-layer-1-91', 'hidden_state-layer-1-92', 'hidden_state-layer-1-93', 'hidden_state-layer-1-94', 'hidden_state-layer-1-95', 'hidden_state-layer-1-96', 'hidden_state-layer-1-97', 'hidden_state-layer-1-98', 'hidden_state-layer-1-99', 'hidden_state-layer-1-100', 'hidden_state-layer-1-101', 'hidden_state-layer-1-102', 'hidden_state-layer-1-103', 'hidden_state-layer-1-104', 'hidden_state-layer-1-105', 'hidden_state-layer-1-106', 'hidden_state-layer-1-107', 'hidden_state-layer-1-108', 'hidden_state-layer-1-109', 'hidden_state-layer-1-110', 'hidden_state-layer-1-111', 'hidden_state-layer-1-112', 'hidden_state-layer-1-113', 'hidden_state-layer-1-114', 'hidden_state-layer-1-115', 'hidden_state-layer-1-116', 'hidden_state-layer-1-117', 'hidden_state-layer-1-118', 'hidden_state-layer-1-119', 'hidden_state-layer-1-120', 'hidden_state-layer-1-121', 'hidden_state-layer-1-122', 'hidden_state-layer-1-123', 'hidden_state-layer-1-124', 'hidden_state-layer-1-125', 'hidden_state-layer-1-126', 'hidden_state-layer-1-127', 'hidden_state-layer-1-128', 'hidden_state-layer-1-129', 'hidden_state-layer-1-130', 'hidden_state-layer-1-131', 'hidden_state-layer-1-132', 'hidden_state-layer-1-133', 'hidden_state-layer-1-134', 'hidden_state-layer-1-135', 'hidden_state-layer-1-136', 'hidden_state-layer-1-137', 'hidden_state-layer-1-138', 'hidden_state-layer-1-139', 'hidden_state-layer-1-140', 'hidden_state-layer-1-141', 'hidden_state-layer-1-142', 'hidden_state-layer-1-143', 'hidden_state-layer-1-144', 'hidden_state-layer-1-145', 'hidden_state-layer-1-146', 'hidden_state-layer-1-147', 'hidden_state-layer-1-148', 'hidden_state-layer-1-149', 'hidden_state-layer-1-150', 'hidden_state-layer-1-151', 'hidden_state-layer-1-152', 'hidden_state-layer-1-153', 'hidden_state-layer-1-154', 'hidden_state-layer-1-155', 'hidden_state-layer-1-156', 'hidden_state-layer-1-157', 'hidden_state-layer-1-158', 'hidden_state-layer-1-159', 'hidden_state-layer-1-160', 'hidden_state-layer-1-161', 'hidden_state-layer-1-162', 'hidden_state-layer-1-163', 'hidden_state-layer-1-164', 'hidden_state-layer-1-165', 'hidden_state-layer-1-166', 'hidden_state-layer-1-167', 'hidden_state-layer-1-168', 'hidden_state-layer-1-169', 'hidden_state-layer-1-170', 'hidden_state-layer-1-171', 'hidden_state-layer-1-172', 'hidden_state-layer-1-173', 'hidden_state-layer-1-174', 'hidden_state-layer-1-175', 'hidden_state-layer-1-176', 'hidden_state-layer-1-177', 'hidden_state-layer-1-178', 'hidden_state-layer-1-179', 'hidden_state-layer-1-180', 'hidden_state-layer-1-181', 'hidden_state-layer-1-182', 'hidden_state-layer-1-183', 'hidden_state-layer-1-184', 'hidden_state-layer-1-185', 'hidden_state-layer-1-186', 'hidden_state-layer-1-187', 'hidden_state-layer-1-188', 'hidden_state-layer-1-189', 'hidden_state-layer-1-190', 'hidden_state-layer-1-191', 'hidden_state-layer-1-192', 'hidden_state-layer-1-193', 'hidden_state-layer-1-194', 'hidden_state-layer-1-195', 'hidden_state-layer-1-196', 'hidden_state-layer-1-197', 'hidden_state-layer-1-198', 'hidden_state-layer-1-199', 'hidden_state-layer-1-200', 'hidden_state-layer-1-201', 'hidden_state-layer-1-202', 'hidden_state-layer-1-203', 'hidden_state-layer-1-204', 'hidden_state-layer-1-205', 'hidden_state-layer-1-206', 'hidden_state-layer-1-207', 'hidden_state-layer-1-208', 'hidden_state-layer-1-209', 'hidden_state-layer-1-210', 'hidden_state-layer-1-211', 'hidden_state-layer-1-212', 'hidden_state-layer-1-213', 'hidden_state-layer-1-214', 'hidden_state-layer-1-215', 'hidden_state-layer-1-216', 'hidden_state-layer-1-217', 'hidden_state-layer-1-218', 'hidden_state-layer-1-219', 'hidden_state-layer-1-220', 'hidden_state-layer-1-221', 'hidden_state-layer-1-222', 'hidden_state-layer-1-223', 'hidden_state-layer-1-224', 'hidden_state-layer-1-225', 'hidden_state-layer-1-226', 'hidden_state-layer-1-227', 'hidden_state-layer-1-228', 'hidden_state-layer-1-229', 'hidden_state-layer-1-230', 'hidden_state-layer-1-231', 'hidden_state-layer-1-232', 'hidden_state-layer-1-233', 'hidden_state-layer-1-234', 'hidden_state-layer-1-235', 'hidden_state-layer-1-236', 'hidden_state-layer-1-237', 'hidden_state-layer-1-238', 'hidden_state-layer-1-239', 'hidden_state-layer-1-240', 'hidden_state-layer-1-241', 'hidden_state-layer-1-242', 'hidden_state-layer-1-243', 'hidden_state-layer-1-244', 'hidden_state-layer-1-245', 'hidden_state-layer-1-246', 'hidden_state-layer-1-247', 'hidden_state-layer-1-248', 'hidden_state-layer-1-249', 'hidden_state-layer-1-250', 'hidden_state-layer-1-251', 'hidden_state-layer-1-252', 'hidden_state-layer-1-253', 'hidden_state-layer-1-254', 'hidden_state-layer-1-255', 'hidden_state-layer-1-256', 'hidden_state-layer-1-257', 'hidden_state-layer-1-258', 'hidden_state-layer-1-259', 'hidden_state-layer-1-260', 'hidden_state-layer-1-261', 'hidden_state-layer-1-262', 'hidden_state-layer-1-263', 'hidden_state-layer-1-264', 'hidden_state-layer-1-265', 'hidden_state-layer-1-266', 'hidden_state-layer-1-267', 'hidden_state-layer-1-268', 'hidden_state-layer-1-269', 'hidden_state-layer-1-270', 'hidden_state-layer-1-271', 'hidden_state-layer-1-272', 'hidden_state-layer-1-273', 'hidden_state-layer-1-274', 'hidden_state-layer-1-275', 'hidden_state-layer-1-276', 'hidden_state-layer-1-277', 'hidden_state-layer-1-278', 'hidden_state-layer-1-279', 'hidden_state-layer-1-280', 'hidden_state-layer-1-281', 'hidden_state-layer-1-282', 'hidden_state-layer-1-283', 'hidden_state-layer-1-284', 'hidden_state-layer-1-285', 'hidden_state-layer-1-286', 'hidden_state-layer-1-287', 'hidden_state-layer-1-288', 'hidden_state-layer-1-289', 'hidden_state-layer-1-290', 'hidden_state-layer-1-291', 'hidden_state-layer-1-292', 'hidden_state-layer-1-293', 'hidden_state-layer-1-294', 'hidden_state-layer-1-295', 'hidden_state-layer-1-296', 'hidden_state-layer-1-297', 'hidden_state-layer-1-298', 'hidden_state-layer-1-299', 'hidden_state-layer-1-300', 'hidden_state-layer-1-301', 'hidden_state-layer-1-302', 'hidden_state-layer-1-303', 'hidden_state-layer-1-304', 'hidden_state-layer-1-305', 'hidden_state-layer-1-306', 'hidden_state-layer-1-307', 'hidden_state-layer-1-308', 'hidden_state-layer-1-309', 'hidden_state-layer-1-310', 'hidden_state-layer-1-311', 'hidden_state-layer-1-312', 'hidden_state-layer-1-313', 'hidden_state-layer-1-314', 'hidden_state-layer-1-315', 'hidden_state-layer-1-316', 'hidden_state-layer-1-317', 'hidden_state-layer-1-318', 'hidden_state-layer-1-319', 'hidden_state-layer-1-320', 'hidden_state-layer-1-321', 'hidden_state-layer-1-322', 'hidden_state-layer-1-323', 'hidden_state-layer-1-324', 'hidden_state-layer-1-325', 'hidden_state-layer-1-326', 'hidden_state-layer-1-327', 'hidden_state-layer-1-328', 'hidden_state-layer-1-329', 'hidden_state-layer-1-330', 'hidden_state-layer-1-331', 'hidden_state-layer-1-332', 'hidden_state-layer-1-333', 'hidden_state-layer-1-334', 'hidden_state-layer-1-335', 'hidden_state-layer-1-336', 'hidden_state-layer-1-337', 'hidden_state-layer-1-338', 'hidden_state-layer-1-339', 'hidden_state-layer-1-340', 'hidden_state-layer-1-341', 'hidden_state-layer-1-342', 'hidden_state-layer-1-343', 'hidden_state-layer-1-344', 'hidden_state-layer-1-345', 'hidden_state-layer-1-346', 'hidden_state-layer-1-347', 'hidden_state-layer-1-348', 'hidden_state-layer-1-349', 'hidden_state-layer-1-350', 'hidden_state-layer-1-351', 'hidden_state-layer-1-352', 'hidden_state-layer-1-353', 'hidden_state-layer-1-354', 'hidden_state-layer-1-355', 'hidden_state-layer-1-356', 'hidden_state-layer-1-357', 'hidden_state-layer-1-358', 'hidden_state-layer-1-359', 'hidden_state-layer-1-360', 'hidden_state-layer-1-361', 'hidden_state-layer-1-362', 'hidden_state-layer-1-363', 'hidden_state-layer-1-364', 'hidden_state-layer-1-365', 'hidden_state-layer-1-366', 'hidden_state-layer-1-367', 'hidden_state-layer-1-368', 'hidden_state-layer-1-369', 'hidden_state-layer-1-370', 'hidden_state-layer-1-371', 'hidden_state-layer-1-372', 'hidden_state-layer-1-373', 'hidden_state-layer-1-374', 'hidden_state-layer-1-375', 'hidden_state-layer-1-376', 'hidden_state-layer-1-377', 'hidden_state-layer-1-378', 'hidden_state-layer-1-379', 'hidden_state-layer-1-380', 'hidden_state-layer-1-381', 'hidden_state-layer-1-382', 'hidden_state-layer-1-383', 'hidden_state-layer-1-384', 'hidden_state-layer-1-385', 'hidden_state-layer-1-386', 'hidden_state-layer-1-387', 'hidden_state-layer-1-388', 'hidden_state-layer-1-389', 'hidden_state-layer-1-390', 'hidden_state-layer-1-391', 'hidden_state-layer-1-392', 'hidden_state-layer-1-393', 'hidden_state-layer-1-394', 'hidden_state-layer-1-395', 'hidden_state-layer-1-396', 'hidden_state-layer-1-397', 'hidden_state-layer-1-398', 'hidden_state-layer-1-399', 'hidden_state-layer-1-400', 'hidden_state-layer-1-401', 'hidden_state-layer-1-402', 'hidden_state-layer-1-403', 'hidden_state-layer-1-404', 'hidden_state-layer-1-405', 'hidden_state-layer-1-406', 'hidden_state-layer-1-407', 'hidden_state-layer-1-408', 'hidden_state-layer-1-409', 'hidden_state-layer-1-410', 'hidden_state-layer-1-411', 'hidden_state-layer-1-412', 'hidden_state-layer-1-413', 'hidden_state-layer-1-414', 'hidden_state-layer-1-415', 'hidden_state-layer-1-416', 'hidden_state-layer-1-417', 'hidden_state-layer-1-418', 'hidden_state-layer-1-419', 'hidden_state-layer-1-420', 'hidden_state-layer-1-421', 'hidden_state-layer-1-422', 'hidden_state-layer-1-423', 'hidden_state-layer-1-424', 'hidden_state-layer-1-425', 'hidden_state-layer-1-426', 'hidden_state-layer-1-427', 'hidden_state-layer-1-428', 'hidden_state-layer-1-429', 'hidden_state-layer-1-430', 'hidden_state-layer-1-431', 'hidden_state-layer-1-432', 'hidden_state-layer-1-433', 'hidden_state-layer-1-434', 'hidden_state-layer-1-435', 'hidden_state-layer-1-436', 'hidden_state-layer-1-437', 'hidden_state-layer-1-438', 'hidden_state-layer-1-439', 'hidden_state-layer-1-440', 'hidden_state-layer-1-441', 'hidden_state-layer-1-442', 'hidden_state-layer-1-443', 'hidden_state-layer-1-444', 'hidden_state-layer-1-445', 'hidden_state-layer-1-446', 'hidden_state-layer-1-447', 'hidden_state-layer-1-448', 'hidden_state-layer-1-449', 'hidden_state-layer-1-450', 'hidden_state-layer-1-451', 'hidden_state-layer-1-452', 'hidden_state-layer-1-453', 'hidden_state-layer-1-454', 'hidden_state-layer-1-455', 'hidden_state-layer-1-456', 'hidden_state-layer-1-457', 'hidden_state-layer-1-458', 'hidden_state-layer-1-459', 'hidden_state-layer-1-460', 'hidden_state-layer-1-461', 'hidden_state-layer-1-462', 'hidden_state-layer-1-463', 'hidden_state-layer-1-464', 'hidden_state-layer-1-465', 'hidden_state-layer-1-466', 'hidden_state-layer-1-467', 'hidden_state-layer-1-468', 'hidden_state-layer-1-469', 'hidden_state-layer-1-470', 'hidden_state-layer-1-471', 'hidden_state-layer-1-472', 'hidden_state-layer-1-473', 'hidden_state-layer-1-474', 'hidden_state-layer-1-475', 'hidden_state-layer-1-476', 'hidden_state-layer-1-477', 'hidden_state-layer-1-478', 'hidden_state-layer-1-479', 'hidden_state-layer-1-480', 'hidden_state-layer-1-481', 'hidden_state-layer-1-482', 'hidden_state-layer-1-483', 'hidden_state-layer-1-484', 'hidden_state-layer-1-485', 'hidden_state-layer-1-486', 'hidden_state-layer-1-487', 'hidden_state-layer-1-488', 'hidden_state-layer-1-489', 'hidden_state-layer-1-490', 'hidden_state-layer-1-491', 'hidden_state-layer-1-492', 'hidden_state-layer-1-493', 'hidden_state-layer-1-494', 'hidden_state-layer-1-495', 'hidden_state-layer-1-496', 'hidden_state-layer-1-497', 'hidden_state-layer-1-498', 'hidden_state-layer-1-499', 'hidden_state-layer-1-500', 'hidden_state-layer-1-501', 'hidden_state-layer-1-502', 'hidden_state-layer-1-503', 'hidden_state-layer-1-504', 'hidden_state-layer-1-505', 'hidden_state-layer-1-506', 'hidden_state-layer-1-507', 'hidden_state-layer-1-508', 'hidden_state-layer-1-509', 'hidden_state-layer-1-510', 'hidden_state-layer-1-511', 'hidden_state-layer-1-512', 'hidden_state-layer-1-513', 'hidden_state-layer-1-514', 'hidden_state-layer-1-515', 'hidden_state-layer-1-516', 'hidden_state-layer-1-517', 'hidden_state-layer-1-518', 'hidden_state-layer-1-519', 'hidden_state-layer-1-520', 'hidden_state-layer-1-521', 'hidden_state-layer-1-522', 'hidden_state-layer-1-523', 'hidden_state-layer-1-524', 'hidden_state-layer-1-525', 'hidden_state-layer-1-526', 'hidden_state-layer-1-527', 'hidden_state-layer-1-528', 'hidden_state-layer-1-529', 'hidden_state-layer-1-530', 'hidden_state-layer-1-531', 'hidden_state-layer-1-532', 'hidden_state-layer-1-533', 'hidden_state-layer-1-534', 'hidden_state-layer-1-535', 'hidden_state-layer-1-536', 'hidden_state-layer-1-537', 'hidden_state-layer-1-538', 'hidden_state-layer-1-539', 'hidden_state-layer-1-540', 'hidden_state-layer-1-541', 'hidden_state-layer-1-542', 'hidden_state-layer-1-543', 'hidden_state-layer-1-544', 'hidden_state-layer-1-545', 'hidden_state-layer-1-546', 'hidden_state-layer-1-547', 'hidden_state-layer-1-548', 'hidden_state-layer-1-549', 'hidden_state-layer-1-550', 'hidden_state-layer-1-551', 'hidden_state-layer-1-552', 'hidden_state-layer-1-553', 'hidden_state-layer-1-554', 'hidden_state-layer-1-555', 'hidden_state-layer-1-556', 'hidden_state-layer-1-557', 'hidden_state-layer-1-558', 'hidden_state-layer-1-559', 'hidden_state-layer-1-560', 'hidden_state-layer-1-561', 'hidden_state-layer-1-562', 'hidden_state-layer-1-563', 'hidden_state-layer-1-564', 'hidden_state-layer-1-565', 'hidden_state-layer-1-566', 'hidden_state-layer-1-567', 'hidden_state-layer-1-568', 'hidden_state-layer-1-569', 'hidden_state-layer-1-570', 'hidden_state-layer-1-571', 'hidden_state-layer-1-572', 'hidden_state-layer-1-573', 'hidden_state-layer-1-574', 'hidden_state-layer-1-575', 'hidden_state-layer-1-576', 'hidden_state-layer-1-577', 'hidden_state-layer-1-578', 'hidden_state-layer-1-579', 'hidden_state-layer-1-580', 'hidden_state-layer-1-581', 'hidden_state-layer-1-582', 'hidden_state-layer-1-583', 'hidden_state-layer-1-584', 'hidden_state-layer-1-585', 'hidden_state-layer-1-586', 'hidden_state-layer-1-587', 'hidden_state-layer-1-588', 'hidden_state-layer-1-589', 'hidden_state-layer-1-590', 'hidden_state-layer-1-591', 'hidden_state-layer-1-592', 'hidden_state-layer-1-593', 'hidden_state-layer-1-594', 'hidden_state-layer-1-595', 'hidden_state-layer-1-596', 'hidden_state-layer-1-597', 'hidden_state-layer-1-598', 'hidden_state-layer-1-599', 'hidden_state-layer-1-600', 'hidden_state-layer-1-601', 'hidden_state-layer-1-602', 'hidden_state-layer-1-603', 'hidden_state-layer-1-604', 'hidden_state-layer-1-605', 'hidden_state-layer-1-606', 'hidden_state-layer-1-607', 'hidden_state-layer-1-608', 'hidden_state-layer-1-609', 'hidden_state-layer-1-610', 'hidden_state-layer-1-611', 'hidden_state-layer-1-612', 'hidden_state-layer-1-613', 'hidden_state-layer-1-614', 'hidden_state-layer-1-615', 'hidden_state-layer-1-616', 'hidden_state-layer-1-617', 'hidden_state-layer-1-618', 'hidden_state-layer-1-619', 'hidden_state-layer-1-620', 'hidden_state-layer-1-621', 'hidden_state-layer-1-622', 'hidden_state-layer-1-623', 'hidden_state-layer-1-624', 'hidden_state-layer-1-625', 'hidden_state-layer-1-626', 'hidden_state-layer-1-627', 'hidden_state-layer-1-628', 'hidden_state-layer-1-629', 'hidden_state-layer-1-630', 'hidden_state-layer-1-631', 'hidden_state-layer-1-632', 'hidden_state-layer-1-633', 'hidden_state-layer-1-634', 'hidden_state-layer-1-635', 'hidden_state-layer-1-636', 'hidden_state-layer-1-637', 'hidden_state-layer-1-638', 'hidden_state-layer-1-639', 'hidden_state-layer-1-640', 'hidden_state-layer-1-641', 'hidden_state-layer-1-642', 'hidden_state-layer-1-643', 'hidden_state-layer-1-644', 'hidden_state-layer-1-645', 'hidden_state-layer-1-646', 'hidden_state-layer-1-647', 'hidden_state-layer-1-648', 'hidden_state-layer-1-649', 'hidden_state-layer-1-650', 'hidden_state-layer-1-651', 'hidden_state-layer-1-652', 'hidden_state-layer-1-653', 'hidden_state-layer-1-654', 'hidden_state-layer-1-655', 'hidden_state-layer-1-656', 'hidden_state-layer-1-657', 'hidden_state-layer-1-658', 'hidden_state-layer-1-659', 'hidden_state-layer-1-660', 'hidden_state-layer-1-661', 'hidden_state-layer-1-662', 'hidden_state-layer-1-663', 'hidden_state-layer-1-664', 'hidden_state-layer-1-665', 'hidden_state-layer-1-666', 'hidden_state-layer-1-667', 'hidden_state-layer-1-668', 'hidden_state-layer-1-669', 'hidden_state-layer-1-670', 'hidden_state-layer-1-671', 'hidden_state-layer-1-672', 'hidden_state-layer-1-673', 'hidden_state-layer-1-674', 'hidden_state-layer-1-675', 'hidden_state-layer-1-676', 'hidden_state-layer-1-677', 'hidden_state-layer-1-678', 'hidden_state-layer-1-679', 'hidden_state-layer-1-680', 'hidden_state-layer-1-681', 'hidden_state-layer-1-682', 'hidden_state-layer-1-683', 'hidden_state-layer-1-684', 'hidden_state-layer-1-685', 'hidden_state-layer-1-686', 'hidden_state-layer-1-687', 'hidden_state-layer-1-688', 'hidden_state-layer-1-689', 'hidden_state-layer-1-690', 'hidden_state-layer-1-691', 'hidden_state-layer-1-692', 'hidden_state-layer-1-693', 'hidden_state-layer-1-694', 'hidden_state-layer-1-695', 'hidden_state-layer-1-696', 'hidden_state-layer-1-697', 'hidden_state-layer-1-698', 'hidden_state-layer-1-699', 'hidden_state-layer-1-700', 'hidden_state-layer-1-701', 'hidden_state-layer-1-702', 'hidden_state-layer-1-703', 'hidden_state-layer-1-704', 'hidden_state-layer-1-705', 'hidden_state-layer-1-706', 'hidden_state-layer-1-707', 'hidden_state-layer-1-708', 'hidden_state-layer-1-709', 'hidden_state-layer-1-710', 'hidden_state-layer-1-711', 'hidden_state-layer-1-712', 'hidden_state-layer-1-713', 'hidden_state-layer-1-714', 'hidden_state-layer-1-715', 'hidden_state-layer-1-716', 'hidden_state-layer-1-717', 'hidden_state-layer-1-718', 'hidden_state-layer-1-719', 'hidden_state-layer-1-720', 'hidden_state-layer-1-721', 'hidden_state-layer-1-722', 'hidden_state-layer-1-723', 'hidden_state-layer-1-724', 'hidden_state-layer-1-725', 'hidden_state-layer-1-726', 'hidden_state-layer-1-727', 'hidden_state-layer-1-728', 'hidden_state-layer-1-729', 'hidden_state-layer-1-730', 'hidden_state-layer-1-731', 'hidden_state-layer-1-732', 'hidden_state-layer-1-733', 'hidden_state-layer-1-734', 'hidden_state-layer-1-735', 'hidden_state-layer-1-736', 'hidden_state-layer-1-737', 'hidden_state-layer-1-738', 'hidden_state-layer-1-739', 'hidden_state-layer-1-740', 'hidden_state-layer-1-741', 'hidden_state-layer-1-742', 'hidden_state-layer-1-743', 'hidden_state-layer-1-744', 'hidden_state-layer-1-745', 'hidden_state-layer-1-746', 'hidden_state-layer-1-747', 'hidden_state-layer-1-748', 'hidden_state-layer-1-749', 'hidden_state-layer-1-750', 'hidden_state-layer-1-751', 'hidden_state-layer-1-752', 'hidden_state-layer-1-753', 'hidden_state-layer-1-754', 'hidden_state-layer-1-755', 'hidden_state-layer-1-756', 'hidden_state-layer-1-757', 'hidden_state-layer-1-758', 'hidden_state-layer-1-759', 'hidden_state-layer-1-760', 'hidden_state-layer-1-761', 'hidden_state-layer-1-762', 'hidden_state-layer-1-763', 'hidden_state-layer-1-764', 'hidden_state-layer-1-765', 'hidden_state-layer-1-766', 'hidden_state-layer-1-767', 'hidden_state-layer-1-768', 'hidden_state-layer-2-1', 'hidden_state-layer-2-2', 'hidden_state-layer-2-3', 'hidden_state-layer-2-4', 'hidden_state-layer-2-5', 'hidden_state-layer-2-6', 'hidden_state-layer-2-7', 'hidden_state-layer-2-8', 'hidden_state-layer-2-9', 'hidden_state-layer-2-10', 'hidden_state-layer-2-11', 'hidden_state-layer-2-12', 'hidden_state-layer-2-13', 'hidden_state-layer-2-14', 'hidden_state-layer-2-15', 'hidden_state-layer-2-16', 'hidden_state-layer-2-17', 'hidden_state-layer-2-18', 'hidden_state-layer-2-19', 'hidden_state-layer-2-20', 'hidden_state-layer-2-21', 'hidden_state-layer-2-22', 'hidden_state-layer-2-23', 'hidden_state-layer-2-24', 'hidden_state-layer-2-25', 'hidden_state-layer-2-26', 'hidden_state-layer-2-27', 'hidden_state-layer-2-28', 'hidden_state-layer-2-29', 'hidden_state-layer-2-30', 'hidden_state-layer-2-31', 'hidden_state-layer-2-32', 'hidden_state-layer-2-33', 'hidden_state-layer-2-34', 'hidden_state-layer-2-35', 'hidden_state-layer-2-36', 'hidden_state-layer-2-37', 'hidden_state-layer-2-38', 'hidden_state-layer-2-39', 'hidden_state-layer-2-40', 'hidden_state-layer-2-41', 'hidden_state-layer-2-42', 'hidden_state-layer-2-43', 'hidden_state-layer-2-44', 'hidden_state-layer-2-45', 'hidden_state-layer-2-46', 'hidden_state-layer-2-47', 'hidden_state-layer-2-48', 'hidden_state-layer-2-49', 'hidden_state-layer-2-50', 'hidden_state-layer-2-51', 'hidden_state-layer-2-52', 'hidden_state-layer-2-53', 'hidden_state-layer-2-54', 'hidden_state-layer-2-55', 'hidden_state-layer-2-56', 'hidden_state-layer-2-57', 'hidden_state-layer-2-58', 'hidden_state-layer-2-59', 'hidden_state-layer-2-60', 'hidden_state-layer-2-61', 'hidden_state-layer-2-62', 'hidden_state-layer-2-63', 'hidden_state-layer-2-64', 'hidden_state-layer-2-65', 'hidden_state-layer-2-66', 'hidden_state-layer-2-67', 'hidden_state-layer-2-68', 'hidden_state-layer-2-69', 'hidden_state-layer-2-70', 'hidden_state-layer-2-71', 'hidden_state-layer-2-72', 'hidden_state-layer-2-73', 'hidden_state-layer-2-74', 'hidden_state-layer-2-75', 'hidden_state-layer-2-76', 'hidden_state-layer-2-77', 'hidden_state-layer-2-78', 'hidden_state-layer-2-79', 'hidden_state-layer-2-80', 'hidden_state-layer-2-81', 'hidden_state-layer-2-82', 'hidden_state-layer-2-83', 'hidden_state-layer-2-84', 'hidden_state-layer-2-85', 'hidden_state-layer-2-86', 'hidden_state-layer-2-87', 'hidden_state-layer-2-88', 'hidden_state-layer-2-89', 'hidden_state-layer-2-90', 'hidden_state-layer-2-91', 'hidden_state-layer-2-92', 'hidden_state-layer-2-93', 'hidden_state-layer-2-94', 'hidden_state-layer-2-95', 'hidden_state-layer-2-96', 'hidden_state-layer-2-97', 'hidden_state-layer-2-98', 'hidden_state-layer-2-99', 'hidden_state-layer-2-100', 'hidden_state-layer-2-101', 'hidden_state-layer-2-102', 'hidden_state-layer-2-103', 'hidden_state-layer-2-104', 'hidden_state-layer-2-105', 'hidden_state-layer-2-106', 'hidden_state-layer-2-107', 'hidden_state-layer-2-108', 'hidden_state-layer-2-109', 'hidden_state-layer-2-110', 'hidden_state-layer-2-111', 'hidden_state-layer-2-112', 'hidden_state-layer-2-113', 'hidden_state-layer-2-114', 'hidden_state-layer-2-115', 'hidden_state-layer-2-116', 'hidden_state-layer-2-117', 'hidden_state-layer-2-118', 'hidden_state-layer-2-119', 'hidden_state-layer-2-120', 'hidden_state-layer-2-121', 'hidden_state-layer-2-122', 'hidden_state-layer-2-123', 'hidden_state-layer-2-124', 'hidden_state-layer-2-125', 'hidden_state-layer-2-126', 'hidden_state-layer-2-127', 'hidden_state-layer-2-128', 'hidden_state-layer-2-129', 'hidden_state-layer-2-130', 'hidden_state-layer-2-131', 'hidden_state-layer-2-132', 'hidden_state-layer-2-133', 'hidden_state-layer-2-134', 'hidden_state-layer-2-135', 'hidden_state-layer-2-136', 'hidden_state-layer-2-137', 'hidden_state-layer-2-138', 'hidden_state-layer-2-139', 'hidden_state-layer-2-140', 'hidden_state-layer-2-141', 'hidden_state-layer-2-142', 'hidden_state-layer-2-143', 'hidden_state-layer-2-144', 'hidden_state-layer-2-145', 'hidden_state-layer-2-146', 'hidden_state-layer-2-147', 'hidden_state-layer-2-148', 'hidden_state-layer-2-149', 'hidden_state-layer-2-150', 'hidden_state-layer-2-151', 'hidden_state-layer-2-152', 'hidden_state-layer-2-153', 'hidden_state-layer-2-154', 'hidden_state-layer-2-155', 'hidden_state-layer-2-156', 'hidden_state-layer-2-157', 'hidden_state-layer-2-158', 'hidden_state-layer-2-159', 'hidden_state-layer-2-160', 'hidden_state-layer-2-161', 'hidden_state-layer-2-162', 'hidden_state-layer-2-163', 'hidden_state-layer-2-164', 'hidden_state-layer-2-165', 'hidden_state-layer-2-166', 'hidden_state-layer-2-167', 'hidden_state-layer-2-168', 'hidden_state-layer-2-169', 'hidden_state-layer-2-170', 'hidden_state-layer-2-171', 'hidden_state-layer-2-172', 'hidden_state-layer-2-173', 'hidden_state-layer-2-174', 'hidden_state-layer-2-175', 'hidden_state-layer-2-176', 'hidden_state-layer-2-177', 'hidden_state-layer-2-178', 'hidden_state-layer-2-179', 'hidden_state-layer-2-180', 'hidden_state-layer-2-181', 'hidden_state-layer-2-182', 'hidden_state-layer-2-183', 'hidden_state-layer-2-184', 'hidden_state-layer-2-185', 'hidden_state-layer-2-186', 'hidden_state-layer-2-187', 'hidden_state-layer-2-188', 'hidden_state-layer-2-189', 'hidden_state-layer-2-190', 'hidden_state-layer-2-191', 'hidden_state-layer-2-192', 'hidden_state-layer-2-193', 'hidden_state-layer-2-194', 'hidden_state-layer-2-195', 'hidden_state-layer-2-196', 'hidden_state-layer-2-197', 'hidden_state-layer-2-198', 'hidden_state-layer-2-199', 'hidden_state-layer-2-200', 'hidden_state-layer-2-201', 'hidden_state-layer-2-202', 'hidden_state-layer-2-203', 'hidden_state-layer-2-204', 'hidden_state-layer-2-205', 'hidden_state-layer-2-206', 'hidden_state-layer-2-207', 'hidden_state-layer-2-208', 'hidden_state-layer-2-209', 'hidden_state-layer-2-210', 'hidden_state-layer-2-211', 'hidden_state-layer-2-212', 'hidden_state-layer-2-213', 'hidden_state-layer-2-214', 'hidden_state-layer-2-215', 'hidden_state-layer-2-216', 'hidden_state-layer-2-217', 'hidden_state-layer-2-218', 'hidden_state-layer-2-219', 'hidden_state-layer-2-220', 'hidden_state-layer-2-221', 'hidden_state-layer-2-222', 'hidden_state-layer-2-223', 'hidden_state-layer-2-224', 'hidden_state-layer-2-225', 'hidden_state-layer-2-226', 'hidden_state-layer-2-227', 'hidden_state-layer-2-228', 'hidden_state-layer-2-229', 'hidden_state-layer-2-230', 'hidden_state-layer-2-231', 'hidden_state-layer-2-232', 'hidden_state-layer-2-233', 'hidden_state-layer-2-234', 'hidden_state-layer-2-235', 'hidden_state-layer-2-236', 'hidden_state-layer-2-237', 'hidden_state-layer-2-238', 'hidden_state-layer-2-239', 'hidden_state-layer-2-240', 'hidden_state-layer-2-241', 'hidden_state-layer-2-242', 'hidden_state-layer-2-243', 'hidden_state-layer-2-244', 'hidden_state-layer-2-245', 'hidden_state-layer-2-246', 'hidden_state-layer-2-247', 'hidden_state-layer-2-248', 'hidden_state-layer-2-249', 'hidden_state-layer-2-250', 'hidden_state-layer-2-251', 'hidden_state-layer-2-252', 'hidden_state-layer-2-253', 'hidden_state-layer-2-254', 'hidden_state-layer-2-255', 'hidden_state-layer-2-256', 'hidden_state-layer-2-257', 'hidden_state-layer-2-258', 'hidden_state-layer-2-259', 'hidden_state-layer-2-260', 'hidden_state-layer-2-261', 'hidden_state-layer-2-262', 'hidden_state-layer-2-263', 'hidden_state-layer-2-264', 'hidden_state-layer-2-265', 'hidden_state-layer-2-266', 'hidden_state-layer-2-267', 'hidden_state-layer-2-268', 'hidden_state-layer-2-269', 'hidden_state-layer-2-270', 'hidden_state-layer-2-271', 'hidden_state-layer-2-272', 'hidden_state-layer-2-273', 'hidden_state-layer-2-274', 'hidden_state-layer-2-275', 'hidden_state-layer-2-276', 'hidden_state-layer-2-277', 'hidden_state-layer-2-278', 'hidden_state-layer-2-279', 'hidden_state-layer-2-280', 'hidden_state-layer-2-281', 'hidden_state-layer-2-282', 'hidden_state-layer-2-283', 'hidden_state-layer-2-284', 'hidden_state-layer-2-285', 'hidden_state-layer-2-286', 'hidden_state-layer-2-287', 'hidden_state-layer-2-288', 'hidden_state-layer-2-289', 'hidden_state-layer-2-290', 'hidden_state-layer-2-291', 'hidden_state-layer-2-292', 'hidden_state-layer-2-293', 'hidden_state-layer-2-294', 'hidden_state-layer-2-295', 'hidden_state-layer-2-296', 'hidden_state-layer-2-297', 'hidden_state-layer-2-298', 'hidden_state-layer-2-299', 'hidden_state-layer-2-300', 'hidden_state-layer-2-301', 'hidden_state-layer-2-302', 'hidden_state-layer-2-303', 'hidden_state-layer-2-304', 'hidden_state-layer-2-305', 'hidden_state-layer-2-306', 'hidden_state-layer-2-307', 'hidden_state-layer-2-308', 'hidden_state-layer-2-309', 'hidden_state-layer-2-310', 'hidden_state-layer-2-311', 'hidden_state-layer-2-312', 'hidden_state-layer-2-313', 'hidden_state-layer-2-314', 'hidden_state-layer-2-315', 'hidden_state-layer-2-316', 'hidden_state-layer-2-317', 'hidden_state-layer-2-318', 'hidden_state-layer-2-319', 'hidden_state-layer-2-320', 'hidden_state-layer-2-321', 'hidden_state-layer-2-322', 'hidden_state-layer-2-323', 'hidden_state-layer-2-324', 'hidden_state-layer-2-325', 'hidden_state-layer-2-326', 'hidden_state-layer-2-327', 'hidden_state-layer-2-328', 'hidden_state-layer-2-329', 'hidden_state-layer-2-330', 'hidden_state-layer-2-331', 'hidden_state-layer-2-332', 'hidden_state-layer-2-333', 'hidden_state-layer-2-334', 'hidden_state-layer-2-335', 'hidden_state-layer-2-336', 'hidden_state-layer-2-337', 'hidden_state-layer-2-338', 'hidden_state-layer-2-339', 'hidden_state-layer-2-340', 'hidden_state-layer-2-341', 'hidden_state-layer-2-342', 'hidden_state-layer-2-343', 'hidden_state-layer-2-344', 'hidden_state-layer-2-345', 'hidden_state-layer-2-346', 'hidden_state-layer-2-347', 'hidden_state-layer-2-348', 'hidden_state-layer-2-349', 'hidden_state-layer-2-350', 'hidden_state-layer-2-351', 'hidden_state-layer-2-352', 'hidden_state-layer-2-353', 'hidden_state-layer-2-354', 'hidden_state-layer-2-355', 'hidden_state-layer-2-356', 'hidden_state-layer-2-357', 'hidden_state-layer-2-358', 'hidden_state-layer-2-359', 'hidden_state-layer-2-360', 'hidden_state-layer-2-361', 'hidden_state-layer-2-362', 'hidden_state-layer-2-363', 'hidden_state-layer-2-364', 'hidden_state-layer-2-365', 'hidden_state-layer-2-366', 'hidden_state-layer-2-367', 'hidden_state-layer-2-368', 'hidden_state-layer-2-369', 'hidden_state-layer-2-370', 'hidden_state-layer-2-371', 'hidden_state-layer-2-372', 'hidden_state-layer-2-373', 'hidden_state-layer-2-374', 'hidden_state-layer-2-375', 'hidden_state-layer-2-376', 'hidden_state-layer-2-377', 'hidden_state-layer-2-378', 'hidden_state-layer-2-379', 'hidden_state-layer-2-380', 'hidden_state-layer-2-381', 'hidden_state-layer-2-382', 'hidden_state-layer-2-383', 'hidden_state-layer-2-384', 'hidden_state-layer-2-385', 'hidden_state-layer-2-386', 'hidden_state-layer-2-387', 'hidden_state-layer-2-388', 'hidden_state-layer-2-389', 'hidden_state-layer-2-390', 'hidden_state-layer-2-391', 'hidden_state-layer-2-392', 'hidden_state-layer-2-393', 'hidden_state-layer-2-394', 'hidden_state-layer-2-395', 'hidden_state-layer-2-396', 'hidden_state-layer-2-397', 'hidden_state-layer-2-398', 'hidden_state-layer-2-399', 'hidden_state-layer-2-400', 'hidden_state-layer-2-401', 'hidden_state-layer-2-402', 'hidden_state-layer-2-403', 'hidden_state-layer-2-404', 'hidden_state-layer-2-405', 'hidden_state-layer-2-406', 'hidden_state-layer-2-407', 'hidden_state-layer-2-408', 'hidden_state-layer-2-409', 'hidden_state-layer-2-410', 'hidden_state-layer-2-411', 'hidden_state-layer-2-412', 'hidden_state-layer-2-413', 'hidden_state-layer-2-414', 'hidden_state-layer-2-415', 'hidden_state-layer-2-416', 'hidden_state-layer-2-417', 'hidden_state-layer-2-418', 'hidden_state-layer-2-419', 'hidden_state-layer-2-420', 'hidden_state-layer-2-421', 'hidden_state-layer-2-422', 'hidden_state-layer-2-423', 'hidden_state-layer-2-424', 'hidden_state-layer-2-425', 'hidden_state-layer-2-426', 'hidden_state-layer-2-427', 'hidden_state-layer-2-428', 'hidden_state-layer-2-429', 'hidden_state-layer-2-430', 'hidden_state-layer-2-431', 'hidden_state-layer-2-432', 'hidden_state-layer-2-433', 'hidden_state-layer-2-434', 'hidden_state-layer-2-435', 'hidden_state-layer-2-436', 'hidden_state-layer-2-437', 'hidden_state-layer-2-438', 'hidden_state-layer-2-439', 'hidden_state-layer-2-440', 'hidden_state-layer-2-441', 'hidden_state-layer-2-442', 'hidden_state-layer-2-443', 'hidden_state-layer-2-444', 'hidden_state-layer-2-445', 'hidden_state-layer-2-446', 'hidden_state-layer-2-447', 'hidden_state-layer-2-448', 'hidden_state-layer-2-449', 'hidden_state-layer-2-450', 'hidden_state-layer-2-451', 'hidden_state-layer-2-452', 'hidden_state-layer-2-453', 'hidden_state-layer-2-454', 'hidden_state-layer-2-455', 'hidden_state-layer-2-456', 'hidden_state-layer-2-457', 'hidden_state-layer-2-458', 'hidden_state-layer-2-459', 'hidden_state-layer-2-460', 'hidden_state-layer-2-461', 'hidden_state-layer-2-462', 'hidden_state-layer-2-463', 'hidden_state-layer-2-464', 'hidden_state-layer-2-465', 'hidden_state-layer-2-466', 'hidden_state-layer-2-467', 'hidden_state-layer-2-468', 'hidden_state-layer-2-469', 'hidden_state-layer-2-470', 'hidden_state-layer-2-471', 'hidden_state-layer-2-472', 'hidden_state-layer-2-473', 'hidden_state-layer-2-474', 'hidden_state-layer-2-475', 'hidden_state-layer-2-476', 'hidden_state-layer-2-477', 'hidden_state-layer-2-478', 'hidden_state-layer-2-479', 'hidden_state-layer-2-480', 'hidden_state-layer-2-481', 'hidden_state-layer-2-482', 'hidden_state-layer-2-483', 'hidden_state-layer-2-484', 'hidden_state-layer-2-485', 'hidden_state-layer-2-486', 'hidden_state-layer-2-487', 'hidden_state-layer-2-488', 'hidden_state-layer-2-489', 'hidden_state-layer-2-490', 'hidden_state-layer-2-491', 'hidden_state-layer-2-492', 'hidden_state-layer-2-493', 'hidden_state-layer-2-494', 'hidden_state-layer-2-495', 'hidden_state-layer-2-496', 'hidden_state-layer-2-497', 'hidden_state-layer-2-498', 'hidden_state-layer-2-499', 'hidden_state-layer-2-500', 'hidden_state-layer-2-501', 'hidden_state-layer-2-502', 'hidden_state-layer-2-503', 'hidden_state-layer-2-504', 'hidden_state-layer-2-505', 'hidden_state-layer-2-506', 'hidden_state-layer-2-507', 'hidden_state-layer-2-508', 'hidden_state-layer-2-509', 'hidden_state-layer-2-510', 'hidden_state-layer-2-511', 'hidden_state-layer-2-512', 'hidden_state-layer-2-513', 'hidden_state-layer-2-514', 'hidden_state-layer-2-515', 'hidden_state-layer-2-516', 'hidden_state-layer-2-517', 'hidden_state-layer-2-518', 'hidden_state-layer-2-519', 'hidden_state-layer-2-520', 'hidden_state-layer-2-521', 'hidden_state-layer-2-522', 'hidden_state-layer-2-523', 'hidden_state-layer-2-524', 'hidden_state-layer-2-525', 'hidden_state-layer-2-526', 'hidden_state-layer-2-527', 'hidden_state-layer-2-528', 'hidden_state-layer-2-529', 'hidden_state-layer-2-530', 'hidden_state-layer-2-531', 'hidden_state-layer-2-532', 'hidden_state-layer-2-533', 'hidden_state-layer-2-534', 'hidden_state-layer-2-535', 'hidden_state-layer-2-536', 'hidden_state-layer-2-537', 'hidden_state-layer-2-538', 'hidden_state-layer-2-539', 'hidden_state-layer-2-540', 'hidden_state-layer-2-541', 'hidden_state-layer-2-542', 'hidden_state-layer-2-543', 'hidden_state-layer-2-544', 'hidden_state-layer-2-545', 'hidden_state-layer-2-546', 'hidden_state-layer-2-547', 'hidden_state-layer-2-548', 'hidden_state-layer-2-549', 'hidden_state-layer-2-550', 'hidden_state-layer-2-551', 'hidden_state-layer-2-552', 'hidden_state-layer-2-553', 'hidden_state-layer-2-554', 'hidden_state-layer-2-555', 'hidden_state-layer-2-556', 'hidden_state-layer-2-557', 'hidden_state-layer-2-558', 'hidden_state-layer-2-559', 'hidden_state-layer-2-560', 'hidden_state-layer-2-561', 'hidden_state-layer-2-562', 'hidden_state-layer-2-563', 'hidden_state-layer-2-564', 'hidden_state-layer-2-565', 'hidden_state-layer-2-566', 'hidden_state-layer-2-567', 'hidden_state-layer-2-568', 'hidden_state-layer-2-569', 'hidden_state-layer-2-570', 'hidden_state-layer-2-571', 'hidden_state-layer-2-572', 'hidden_state-layer-2-573', 'hidden_state-layer-2-574', 'hidden_state-layer-2-575', 'hidden_state-layer-2-576', 'hidden_state-layer-2-577', 'hidden_state-layer-2-578', 'hidden_state-layer-2-579', 'hidden_state-layer-2-580', 'hidden_state-layer-2-581', 'hidden_state-layer-2-582', 'hidden_state-layer-2-583', 'hidden_state-layer-2-584', 'hidden_state-layer-2-585', 'hidden_state-layer-2-586', 'hidden_state-layer-2-587', 'hidden_state-layer-2-588', 'hidden_state-layer-2-589', 'hidden_state-layer-2-590', 'hidden_state-layer-2-591', 'hidden_state-layer-2-592', 'hidden_state-layer-2-593', 'hidden_state-layer-2-594', 'hidden_state-layer-2-595', 'hidden_state-layer-2-596', 'hidden_state-layer-2-597', 'hidden_state-layer-2-598', 'hidden_state-layer-2-599', 'hidden_state-layer-2-600', 'hidden_state-layer-2-601', 'hidden_state-layer-2-602', 'hidden_state-layer-2-603', 'hidden_state-layer-2-604', 'hidden_state-layer-2-605', 'hidden_state-layer-2-606', 'hidden_state-layer-2-607', 'hidden_state-layer-2-608', 'hidden_state-layer-2-609', 'hidden_state-layer-2-610', 'hidden_state-layer-2-611', 'hidden_state-layer-2-612', 'hidden_state-layer-2-613', 'hidden_state-layer-2-614', 'hidden_state-layer-2-615', 'hidden_state-layer-2-616', 'hidden_state-layer-2-617', 'hidden_state-layer-2-618', 'hidden_state-layer-2-619', 'hidden_state-layer-2-620', 'hidden_state-layer-2-621', 'hidden_state-layer-2-622', 'hidden_state-layer-2-623', 'hidden_state-layer-2-624', 'hidden_state-layer-2-625', 'hidden_state-layer-2-626', 'hidden_state-layer-2-627', 'hidden_state-layer-2-628', 'hidden_state-layer-2-629', 'hidden_state-layer-2-630', 'hidden_state-layer-2-631', 'hidden_state-layer-2-632', 'hidden_state-layer-2-633', 'hidden_state-layer-2-634', 'hidden_state-layer-2-635', 'hidden_state-layer-2-636', 'hidden_state-layer-2-637', 'hidden_state-layer-2-638', 'hidden_state-layer-2-639', 'hidden_state-layer-2-640', 'hidden_state-layer-2-641', 'hidden_state-layer-2-642', 'hidden_state-layer-2-643', 'hidden_state-layer-2-644', 'hidden_state-layer-2-645', 'hidden_state-layer-2-646', 'hidden_state-layer-2-647', 'hidden_state-layer-2-648', 'hidden_state-layer-2-649', 'hidden_state-layer-2-650', 'hidden_state-layer-2-651', 'hidden_state-layer-2-652', 'hidden_state-layer-2-653', 'hidden_state-layer-2-654', 'hidden_state-layer-2-655', 'hidden_state-layer-2-656', 'hidden_state-layer-2-657', 'hidden_state-layer-2-658', 'hidden_state-layer-2-659', 'hidden_state-layer-2-660', 'hidden_state-layer-2-661', 'hidden_state-layer-2-662', 'hidden_state-layer-2-663', 'hidden_state-layer-2-664', 'hidden_state-layer-2-665', 'hidden_state-layer-2-666', 'hidden_state-layer-2-667', 'hidden_state-layer-2-668', 'hidden_state-layer-2-669', 'hidden_state-layer-2-670', 'hidden_state-layer-2-671', 'hidden_state-layer-2-672', 'hidden_state-layer-2-673', 'hidden_state-layer-2-674', 'hidden_state-layer-2-675', 'hidden_state-layer-2-676', 'hidden_state-layer-2-677', 'hidden_state-layer-2-678', 'hidden_state-layer-2-679', 'hidden_state-layer-2-680', 'hidden_state-layer-2-681', 'hidden_state-layer-2-682', 'hidden_state-layer-2-683', 'hidden_state-layer-2-684', 'hidden_state-layer-2-685', 'hidden_state-layer-2-686', 'hidden_state-layer-2-687', 'hidden_state-layer-2-688', 'hidden_state-layer-2-689', 'hidden_state-layer-2-690', 'hidden_state-layer-2-691', 'hidden_state-layer-2-692', 'hidden_state-layer-2-693', 'hidden_state-layer-2-694', 'hidden_state-layer-2-695', 'hidden_state-layer-2-696', 'hidden_state-layer-2-697', 'hidden_state-layer-2-698', 'hidden_state-layer-2-699', 'hidden_state-layer-2-700', 'hidden_state-layer-2-701', 'hidden_state-layer-2-702', 'hidden_state-layer-2-703', 'hidden_state-layer-2-704', 'hidden_state-layer-2-705', 'hidden_state-layer-2-706', 'hidden_state-layer-2-707', 'hidden_state-layer-2-708', 'hidden_state-layer-2-709', 'hidden_state-layer-2-710', 'hidden_state-layer-2-711', 'hidden_state-layer-2-712', 'hidden_state-layer-2-713', 'hidden_state-layer-2-714', 'hidden_state-layer-2-715', 'hidden_state-layer-2-716', 'hidden_state-layer-2-717', 'hidden_state-layer-2-718', 'hidden_state-layer-2-719', 'hidden_state-layer-2-720', 'hidden_state-layer-2-721', 'hidden_state-layer-2-722', 'hidden_state-layer-2-723', 'hidden_state-layer-2-724', 'hidden_state-layer-2-725', 'hidden_state-layer-2-726', 'hidden_state-layer-2-727', 'hidden_state-layer-2-728', 'hidden_state-layer-2-729', 'hidden_state-layer-2-730', 'hidden_state-layer-2-731', 'hidden_state-layer-2-732', 'hidden_state-layer-2-733', 'hidden_state-layer-2-734', 'hidden_state-layer-2-735', 'hidden_state-layer-2-736', 'hidden_state-layer-2-737', 'hidden_state-layer-2-738', 'hidden_state-layer-2-739', 'hidden_state-layer-2-740', 'hidden_state-layer-2-741', 'hidden_state-layer-2-742', 'hidden_state-layer-2-743', 'hidden_state-layer-2-744', 'hidden_state-layer-2-745', 'hidden_state-layer-2-746', 'hidden_state-layer-2-747', 'hidden_state-layer-2-748', 'hidden_state-layer-2-749', 'hidden_state-layer-2-750', 'hidden_state-layer-2-751', 'hidden_state-layer-2-752', 'hidden_state-layer-2-753', 'hidden_state-layer-2-754', 'hidden_state-layer-2-755', 'hidden_state-layer-2-756', 'hidden_state-layer-2-757', 'hidden_state-layer-2-758', 'hidden_state-layer-2-759', 'hidden_state-layer-2-760', 'hidden_state-layer-2-761', 'hidden_state-layer-2-762', 'hidden_state-layer-2-763', 'hidden_state-layer-2-764', 'hidden_state-layer-2-765', 'hidden_state-layer-2-766', 'hidden_state-layer-2-767', 'hidden_state-layer-2-768']\",\n",
       "   'surname': 'bert-base-uncased_L-2_H-768_A-12_pre-20_norm-2_hidden-layer-[1, 2]',\n",
       "   'data_compression': None,\n",
       "   'ncomponents': 0,\n",
       "   'offset_type': 'word+punctuation',\n",
       "   'duration_type': None,\n",
       "   'shift_surprisal': False,\n",
       "   'centering': 'True',\n",
       "   'order': None,\n",
       "   'scaling_type': None,\n",
       "   'input_template': 'activations'}],\n",
       " 'model_name': 'bert-base-uncased_L-2_H-768_A-12_pre-20_norm-2_norm-None_temporal-shifting-0_115_hidden-all-layers_alpha-100'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/bert-base-uncased_pre-2_1_post-0_norm-None/activations_run1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[columns[:13*768]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ortho_proj(Y, M):\n",
    "    \"\"\" returns the orthogonal component of Y to the space spanned by M and the constant vector 1 \"\"\"\n",
    "    if M.ndim == 1:   # M is a vector but needs to be a 2-D matrix\n",
    "        M = M[:, np.newaxis]\n",
    "    I = np.ones(len(M))\n",
    "    I = I[:, np.newaxis]\n",
    "    M2 = np.hstack((I, M))  # adding the constant \n",
    "    betas,_,_,_ = np.linalg.lstsq(M2, Y)\n",
    "    Xc = np.dot(M2, betas)  # colinear component \"residuals\"\n",
    "    Xo = Y - Xc\n",
    "    return Xo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/volatile/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  \n",
      "551it [03:14,  1.16s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-fcf736d8cc3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mortho_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-e58e68ca04ba>\u001b[0m in \u001b[0;36mortho_proj\u001b[0;34m(Y, M)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mM2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# adding the constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mXc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# colinear component \"residuals\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mXo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mXc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/volatile/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DDd->Ddid'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'ddd->ddid'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0;31m# remove the axis we added\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columns_d = d.columns\n",
    "result = []\n",
    "for index, c in tqdm(enumerate(columns_d)):\n",
    "    if index==0:\n",
    "        result.append(d[c].values-np.mean(d[c].values))\n",
    "    else:\n",
    "        result.append(ortho_proj(d[c].values, d[columns_d[:index]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.vstack(result).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1894, 551)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
