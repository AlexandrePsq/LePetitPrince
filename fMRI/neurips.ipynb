{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook generating plots for NeurIPS paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import nistats\n",
    "import scipy\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "from nilearn.image import load_img, mean_img, index_img, threshold_img, math_img, smooth_img, new_img_like\n",
    "from nilearn.input_data import NiftiMapsMasker, NiftiMasker, NiftiLabelsMasker, MultiNiftiMasker\n",
    "from nilearn.regions import RegionExtractor\n",
    "from nistats.second_level_model import SecondLevelModel\n",
    "from nistats.thresholding import map_threshold\n",
    "from nilearn import plotting\n",
    "from nilearn import datasets\n",
    "from scipy.stats import norm\n",
    "from nilearn.surface import vol_to_surf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import Logger\n",
    "from utils import read_yaml, check_folder, fetch_masker, possible_subjects_id, get_subject_name\n",
    "import reporting\n",
    "from linguistics_info import load_surnames, load_syntactic_roi, load_language_roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = f\"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/\"\n",
    "OUTPUT_PATH = f\"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/maps/{language}\"\n",
    "INPUT_PATH = f\"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{language}\"\n",
    "FMRIDATA_PATH = f\"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/fMRI/{language}\"\n",
    "MASKER_PATH = f\"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/global_masker_{language}\"\n",
    "SMOOTHED_MASKER_PATH = f\"/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/smoothed_global_masker_{language}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch a masker fitted on all subjects data and the following characterisctics:\n",
    "- detrend: true\n",
    "- dtype: null\n",
    "- high_pass: null\n",
    "- low_pass: null\n",
    "- mask_strategy: background\n",
    "- memory_level: 0\n",
    "- n_jobs: 1\n",
    "- smoothing_fwhm: null\n",
    "- standardize: true\n",
    "- t_r: null\n",
    "- verbose: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = reporting.fetch_masker(MASKER_PATH, language, FMRIDATA_PATH, INPUT_PATH, smoothing_fwhm=None, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_maps, labels = reporting.load_atlas() # load harvard-oxford atlas named'cort-prob-2mm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'glove_300_{}',\n",
    "    'LSTM_embedding-size_600_nhid_300_nlayers_1_dropout_02_wiki_kristina_english_{}_all-hidden-layers',\n",
    "    'gpt2_scaled_{}_all-hidden-layers_pca_300',\n",
    "    'bert-base-cased_{}_all-hidden-layers_pca_300',\n",
    "    'BF_rms_{}',\n",
    "    'BF_log_frequency_{}',\n",
    "    'BF_wordrate_{}',\n",
    "    'BF_content_words_{}',\n",
    "    'BF_function_words_{}',\n",
    "    'BF_word_position_{}'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = reporting.get_model_data(model_names, language, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if we have all the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting.check_data(data_full, 51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing group level maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting.compute_t_test_for_model_comparison(\n",
    "                                        data_full, \n",
    "                                        smoothing_fwhm=6, \n",
    "                                        language='english',\n",
    "                                        vmax=None,\n",
    "                                        PROJECT_PATH='/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/'\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison (GloVe - LSTM - GPT2 - BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'glove_300_{}',\n",
    "    'LSTM_embedding-size_600_nhid_300_nlayers_1_dropout_02_wiki_kristina_english_{}_all-hidden-layers',\n",
    "    'gpt2_scaled_{}_all-hidden-layers_pca_300',\n",
    "    'bert-base-cased_{}_all-hidden-layers_pca_300'\n",
    "]\n",
    "\n",
    "legend_names = ['GloVe', \n",
    "                'LSTM-E600-H300-L1', \n",
    "                'GPT2_scaled(Hpca)', \n",
    "                'BERT(Hpca)'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_comparison = data_full[model_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing data for plot per ROI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_vertical = reporting.get_data_per_roi(\n",
    "                                data_model_comparison, \n",
    "                                atlas_maps,\n",
    "                                labels,\n",
    "                                analysis=None, \n",
    "                                language='english', \n",
    "                                PROJECT_PATH='/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = data_prep_vertical['mean']\n",
    "third_quartile = data_prep_vertical['third_quartile']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertical plots per ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting.vertical_plot(\n",
    "                mean, \n",
    "                x_labels, \n",
    "                'Mean_R2_per_ROI',\n",
    "                save_folder=None, \n",
    "                'R2', \n",
    "                reporting.load_surnames(),\n",
    "                legend_names, \n",
    "                reporting.load_syntactic_roi(), \n",
    "                reporting.load_language_roi(), \n",
    "                figsize=(9,12), \n",
    "                count=False, \n",
    "                title=None, \n",
    "                ylabel='Regions of interest (ROI)', \n",
    "                xlabel='R2 value', \n",
    "                model_name='Model_comparison'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting.vertical_plot(\n",
    "                third_quartile, \n",
    "                x_labels, \n",
    "                'Third_Quartile_R2_per_ROI',\n",
    "                save_folder=None, \n",
    "                'R2', \n",
    "                reporting.load_surnames(),\n",
    "                legend_names, \n",
    "                reporting.load_syntactic_roi(), \n",
    "                reporting.load_language_roi(), \n",
    "                figsize=(9,12), \n",
    "                count=False, \n",
    "                title=None, \n",
    "                ylabel='Regions of interest (ROI)', \n",
    "                xlabel='R2 value', \n",
    "                model_name='Model_comparison'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Surface plots showing which model predicts better (voxel-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'glove_300',\n",
    "    'LSTM_embedding-size_600_nhid_300_nlayers_1_dropout_02_wiki_kristina_english_all-hidden-layers',\n",
    "    'gpt2_scaled_all-hidden-layers_pca_300',\n",
    "    'bert-base-cased_all-hidden-layers_pca_300'\n",
    "]\n",
    "data_prep_surf = reporting.get_group_level_analysis_data(\n",
    "                                            masker, \n",
    "                                            model_names, \n",
    "                                            language='english', \n",
    "                                            PROJECT_PATH='/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'surf_mesh': 'pial_left', # pial_right, infl_left, infl_right\n",
    "    'surf_mesh_type': 'pial_left',\n",
    "    'hemi':'left', # right\n",
    "    'view':'lateral', # medial\n",
    "    'bg_map': 'sulc_left', # sulc_right\n",
    "    'bg_on_data':True,\n",
    "    'darkness':.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = reporting.get_voxel_wise_max_img(\n",
    "                            masker, \n",
    "                            model_names, \n",
    "                            language='english', \n",
    "                            PROJECT_PATH='/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting.plot_roi_img_surf(img, saving_path, 'model_comparison_surf', inflated=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting.interactive_surf_plot(img, inflated=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Surface plots of group-level difference analysis maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = {\n",
    "    'LSTM_300-H_vs_Glove' : ['LSTM_embedding-size_600_nhid_300_nlayers_1_dropout_02_wiki_kristina_english_all-hidden-layers', 'glove_300'],\n",
    "    'BERT-Hpca_vs_GPT2-scaled-Hpca' : ['bert-base-cased_all-hidden-layers_pca_300', 'gpt2_scaled_all-hidden-layers_pca_300'],\n",
    "    'BERT-Hpca_vs_LSTM_300-H' : ['bert-base-cased_all-hidden-layers_pca_300', 'LSTM_embedding-size_600_nhid_300_nlayers_1_dropout_02_wiki_kristina_english_all-hidden-layers'],\n",
    "    'GPT2-scaled-Hpca_vs_LSTM_300-H' : ['gpt2_scaled_all-hidden-layers_pca_300', 'LSTM_embedding-size_600_nhid_300_nlayers_1_dropout_02_wiki_kristina_english_all-hidden-layers'],\n",
    "    'BERT-Hpca_vs_Glove' : ['bert-base-cased_all-hidden-layers_pca_300', 'glove_300'],\n",
    "    'GPT2-scaled-Hpca_vs_Glove' : ['gpt2_scaled_all-hidden-layers_pca_300', 'glove_300']   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comparison in comparisons:\n",
    "    imgs_1 = data_full[comparisons[comparison][0]]['R2']\n",
    "    imgs_2 = data_full[comparisons[comparison][1]]['R2']\n",
    "    \n",
    "    names = comparison.split('_vs_')\n",
    "\n",
    "    reporting.compute_model_contrasts_t_test(\n",
    "                                    imgs_1,\n",
    "                                    imgs_2,\n",
    "                                    names[0], \n",
    "                                    names[1], \n",
    "                                    analysis_name='',\n",
    "                                    observed_data='R2',\n",
    "                                    language='english',\n",
    "                                    smoothing_fwhm=6,\n",
    "                                    PROJECT_PATH='/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/'\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {}\n",
    "for comparison in comparisons:\n",
    "    names = comparison.split('_vs_')\n",
    "    name = '{}-vs-{}_{}'.format(names[0], names[1], '')\n",
    "    path = os.path.join(PROJECT_PATH, 'derivatives/fMRI/analysis/{}/{}'.format(language, name))\n",
    "    paths[comparison] = reporting.fetch_map(path, 'R2_group_fdr_effect')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'surf_mesh': 'pial_left', # pial_right, infl_left, infl_right\n",
    "    'surf_mesh_type': 'pial_left',\n",
    "    'hemi':'left', # right\n",
    "    'view':'lateral', # medial\n",
    "    'bg_map': 'sulc_left', # sulc_right\n",
    "    'bg_on_data':True,\n",
    "    'darkness':.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_comp, comparison in enumerate(comparisons):\n",
    "    saving_path = os.path.dirname(paths[index_comp])\n",
    "    plot_img_surf(paths[index_comp], saving_path, comparison + '_surf', inflated=False, **kwargs):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT vs GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
