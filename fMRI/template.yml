# Shared General parameters
subject: 57
parallel: False
cuda: True
seed: 1111
language: english
path_to_root: "/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/"
path_to_fmridata: "/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/fMRI"
output: "/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/maps/"  # Path to the output folder
input: "/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/"  # Path to the folder containing the representations
detrend: True
standardize: True
high_pass: 
low_pass: 
mask_strategy: background
#dtype: float32
memory_level: 0
smoothing_fwhm:  
verbose: 0

# Shared Splitter parameters
nb_runs: 9
nb_runs_test: 1

# Shared Compression parameters


# Shared Transformation parameters (includes the making of regressor and scaling)
tr: 2.
scaling_mean: True
scaling_var: True
scaling_axis: 1
hrf: spm
offset_path: "/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/onsets-offsets/"
duration_path: "/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/"
temporal_shifting: 0

# Shared Estimator model parameters
base: 10.0
voxel_wise: True
alpha_percentile: 99.9
alpha:
alpha_min_log_scale: 2
alpha_max_log_scale: 5
nb_alphas: 10
optimizing_criteria: R2
estimator_model: Ridge()

# Maps creation parameters
atlas: cort-prob-2mm
masker_path: "/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/global_masker_english"
smoothed_masker_path: "/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/smoothed_global_masker_english"


# Models
models:
  - model_name: Bert-base-cased
    columns_to_retrieve: "['hidden_state-layer-12-{}'.format(i) for i in range(1, 769)]"
    input_template: activations # cls / sep
    surname: Bert
    data_compression: 
    ncomponents: 
    offset_type: 'word+punctuation' # word / word+punctuation / ...
    duration_type: 
    shift_surprisal: False
    centering: True
    order: 2
    scaling_type: normalize
  - model_name: Bert-base-cased
    columns_to_retrieve: "['hidden_state-layer-11-{}'.format(i) for i in range(1, 769)]"
    input_template: activations # cls / sep
    surname: Bert
    data_compression: 
    ncomponents: 
    offset_type: 'word+punctuation' # word / word+punctuation / ...
    duration_type: 
    shift_surprisal: False
    centering: True
    order: 2
    scaling_type: normalize
  - model_name: wordrate_all_model
    columns_to_retrieve: "[3]"
    surname: unigram
    data_compression: 
    ncomponents: 
    offset_type: 'word' # word / word+punctuation / ...
    duration_type: 
    shift_surprisal: False
    centering:
    order:
    scaling_type:
model_name: BERT-L11-12+Wordrate
