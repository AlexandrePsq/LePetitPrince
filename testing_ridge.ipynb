{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities.settings import Paths, Subjects, Extensions, Params\n",
    "import pandas as pd\n",
    "from nilearn.masking import compute_epi_mask\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from nilearn.image import math_img, mean_img\n",
    "from joblib import Parallel, delayed\n",
    "from nilearn.input_data import MultiNiftiMasker\n",
    "from nilearn.plotting import plot_glass_brain\n",
    "from sklearn.model_selection import LeaveOneOut, LeaveOneGroupOut\n",
    "from nilearn.image import math_img, mean_img\n",
    "import nibabel as nib\n",
    "from utilities.splitter import Splitter\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "paths = Paths()\n",
    "subjects_list = Subjects()\n",
    "params = Params()\n",
    "extensions= Extensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'fMRI'\n",
    "input_data_type = 'design-matrices'\n",
    "output_data_type = 'ridge-indiv'\n",
    "alphas = np.logspace(-3, 1, 30)\n",
    "model = Ridge(alpha=0.1)\n",
    "model_name = 'lstm_wikikristina_embedding-size_200_nhid_100_nlayers_3_dropout_01'\n",
    "subjects = ['sub-057']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "############ Data retrieving ############\n",
    "#########################################\n",
    "\n",
    "def get_data(language, data_type, subject=None, source='', model=''):\n",
    "    # General function for data retrieving\n",
    "    # Output: list of path to the different data files\n",
    "    extension = extensions.get_extension(data_type)\n",
    "    sub_dir = os.listdir(paths.path2data)\n",
    "    if data_type in sub_dir:\n",
    "        base_path = paths.path2data\n",
    "        if data_type in ['fMRI', 'MEG']:\n",
    "            file_pattern = '{2}/func/{0}_{1}_{2}_run*'.format(data_type, language, subject) + extension\n",
    "        else:\n",
    "            file_pattern = '{}_{}_{}_run*'.format(data_type, language, model) + extension\n",
    "    else:\n",
    "        base_path = join(paths.path2derivatives, source)\n",
    "        file_pattern = '{}_{}_{}_run*'.format(data_type, language, model) + extension\n",
    "    data = sorted(glob.glob(join(base_path, '{0}/{1}/{2}'.format(data_type, language, model), file_pattern)))\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_output_parent_folder(source, output_data_type, language, model):\n",
    "    return join(paths.path2derivatives, '{0}/{1}/{2}/{3}'.format(source, output_data_type, language, model))\n",
    "\n",
    "\n",
    "def get_path2output(output_parent_folder, output_data_type, language, model, run_name, extension):\n",
    "    return join(output_parent_folder, '{0}_{1}_{2}_{3}'.format(output_data_type, language, model, run_name) + extension)\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "###### Computation functionalities ######\n",
    "#########################################\n",
    "\n",
    "def compute(path, overwrite=False):\n",
    "    # Tell us if we can compute or not\n",
    "    result = True\n",
    "    if os.path.isfile(path):\n",
    "        result = overwrite\n",
    "    return result\n",
    "\n",
    "\n",
    "def check_folder(path):\n",
    "    # Create adequate folders if necessary\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "################## Log ##################\n",
    "#########################################\n",
    "\n",
    "def log(subject, voxel, alpha, r2):\n",
    "    \"\"\" log stats per fold to a csv file \"\"\"\n",
    "    logcsvwriter = csv.writer(open(\"test.log\", \"a+\"))\n",
    "    if voxel == 'whole brain':\n",
    "        logcsvwriter.writerow([subject, voxel, np.mean(r2), np.std(r2),\n",
    "                            np.min(r2), np.max(r2)])\n",
    "    else:\n",
    "        logcsvwriter.writerow([subject, voxel, alpha, r2])\n",
    "\n",
    "\n",
    "#########################################\n",
    "########## Classical functions ##########\n",
    "#########################################\n",
    "def get_r2_score(model, y_true, y2predict, r2_min=0., r2_max=0.99):\n",
    "    # return the R2_score for each voxel (=list)\n",
    "    r2 = r2_score(y_true,\n",
    "                    model.predict(y2predict),\n",
    "                    multioutput='raw_values')\n",
    "    # remove values with are too low and values too good to be true (e.g. voxels without variation)\n",
    "    return np.array([0 if (x < r2_min or x >= r2_max) else x for x in r2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "################ Figures ################\n",
    "#########################################\n",
    "\n",
    "def create_maps(masker, distribution, distribution_name, subject, output_parent_folder):\n",
    "    model = os.path.basename(output_parent_folder)\n",
    "    language = os.path.basename(os.path.dirname(output_parent_folder))\n",
    "    data_type = os.path.basename(os.path.dirname(os.path.dirname(output_parent_folder)))\n",
    "\n",
    "    img = masker.inverse_transform(distribution)\n",
    "    \n",
    "    path2output_raw = join(output_parent_folder, \"{0}_{1}_{2}_{3}_{4}\".format(data_type, language, model, distribution_name, subject)+'.nii.gz')\n",
    "    path2output_png = join(output_parent_folder, \"{0}_{1}_{2}_{3}_{4}\".format(data_type, language, model, distribution_name, subject)+'.png')\n",
    "\n",
    "    nib.save(img, path2output_raw)\n",
    "\n",
    "    display = plot_glass_brain(img, display_mode='lzry', threshold=0, colorbar=True)\n",
    "    display.savefig(path2output_png)\n",
    "    display.close()\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "######### First level analysis ##########\n",
    "#########################################\n",
    "\n",
    "\n",
    "\n",
    "def do_single_subject(subject, fmri_filenames, design_matrices, masker, output_parent_folder, model, voxel_wised=False, alpha_list=np.logspace(-3, -1, 30)):\n",
    "    # Compute r2 maps for all subject for a given model\n",
    "    #   - subject : e.g. : 'sub-060'\n",
    "    #   - fmri_runs: list of fMRI data runs (1 for each run)\n",
    "    #   - matrices: list of design matrices (1 for each run)\n",
    "    #   - masker: MultiNiftiMasker object\n",
    "    fmri_runs = [masker.transform(f) for f in fmri_filenames] # return a list of 2D matrices with the values of the voxels in the mask: 1 voxel per column\n",
    "    \n",
    "    # compute r2 maps and save them under .nii.gz and .png formats\n",
    "    if voxel_wised:\n",
    "        alphas, r2_test = per_voxel_analysis(model, fmri_runs, design_matrices, subject, alpha_list)\n",
    "        create_maps(masker, alphas, 'alphas', subject, output_parent_folder) # alphas\n",
    "    else:\n",
    "        r2_test = whole_brain_analysis(model, fmri_runs, design_matrices, subject)\n",
    "    create_maps(masker, r2_test, 'r2_test', subject, output_parent_folder) # r2 test\n",
    "\n",
    "\n",
    "def whole_brain_analysis(model, fmri_runs, design_matrices, subject):\n",
    "    #   - fmri_runs: list of fMRI data runs (1 for each run)\n",
    "    #   - matrices: list of design matrices (1 for each run)\n",
    "    scores = None  # array to contain the r2 values (1 row per fold, 1 column per voxel)\n",
    "    nb_runs = len(fmri_runs)\n",
    "    \n",
    "    for index in range(len(design_matrices)):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(design_matrices[index])\n",
    "        design_matrices[index] = scaler.transform(design_matrices[index])\n",
    "        const = np.ones((design_matrices[index].shape[0], 1))\n",
    "        design_matrices[index] = np.hstack((design_matrices[index], const))\n",
    "\n",
    "    logo = LeaveOneGroupOut() # leave on run out !\n",
    "    for train, test in tqdm(logo.split(fmri_runs, groups=range(1, nb_runs+1))):\n",
    "        fmri_data_train = np.vstack([fmri_runs[i] for i in train]) # fmri_runs liste 2D colonne = voxels et chaque row = un t_i\n",
    "        predictors_train = np.vstack([design_matrices[i] for i in train])\n",
    "\n",
    "        if type(model) == sklearn.linear_model.RidgeCV or type(model) == sklearn.linear_model.Ridge:\n",
    "            print()\n",
    "            #nb_samples = np.cumsum([0] + [[fmri_runs[i] for i in train][i].shape[0] for i in range(len([fmri_runs[i] for i in train]))]) # list of cumulative lenght\n",
    "            #indexes = {'run{}'.format(run+1): [nb_samples[i], nb_samples[i+1]] for i, run in enumerate(train)}\n",
    "            #model.cv = Splitter(indexes_dict=indexes, n_splits=nb_runs-1) # adequate splitter for cross-validate alpha taking into account groups\n",
    "        print('Fitting model...')\n",
    "        print(predictors_train)\n",
    "        model_fitted = model.fit(predictors_train, fmri_data_train)\n",
    "        pickle.dump(model_fitted, open(join(paths.path2derivatives, 'fMRI/glm-indiv/english', str(model).split('(')[0]+ '{}.sav'.format(test[0])), 'wb'))\n",
    "        print('Model fitted.')\n",
    "\n",
    "        # return the R2_score for each voxel (=list)\n",
    "        r2 = get_r2_score(model_fitted, fmri_runs[test[0]], design_matrices[test[0]])\n",
    "        print(r2)\n",
    "        print(scores)\n",
    "\n",
    "        # log the results\n",
    "        log(subject, voxel='whole brain', alpha=None, r2=r2)\n",
    "\n",
    "        scores = r2 if scores is None else np.vstack([scores, r2])\n",
    "    result = pd.DataFrame(scores, columns=['voxel #{}'.format(i) for i in range(scores.shape[1])])\n",
    "    result.to_csv(join(paths.path2derivatives, 'fMRI/glm-indiv/english', str(model).split('(')[0]+ '.csv'))\n",
    "    return np.mean(scores, axis=0) # compute mean vertically (in time)\n",
    "\n",
    "\n",
    "def per_voxel_analysis(model, fmri_runs, design_matrices, subject, alpha_list):\n",
    "    # compute alphas and test score with cross validation\n",
    "    #   - fmri_runs: list of fMRI data runs (1 for each run)\n",
    "    #   - design_matrices: list of design matrices (1 for each run)\n",
    "    #   - nb_voxels: number of voxels\n",
    "    #   - indexes: dict specifying row indexes for each run\n",
    "    nb_voxels = fmri_runs[0].shape[1]\n",
    "    nb_alphas = len(alpha_list)\n",
    "    nb_runs_test = len(fmri_runs)\n",
    "    nb_runs_valid = nb_runs_test -1 \n",
    "    alphas_cv2 = np.zeros((nb_runs_test, nb_voxels))\n",
    "    scores_cv2 = np.zeros((nb_runs_test, nb_voxels))\n",
    "    \n",
    "    # loop for r2 computation\n",
    "    cv3 = 0\n",
    "    logo = LeaveOneOut() # leave on run out !\n",
    "    for train_, test in logo.split(fmri_runs):\n",
    "        fmri_data_train_ = [fmri_runs[i] for i in train_] # fmri_runs liste 2D colonne = voxels et chaque row = un t_i\n",
    "        predictors_train_ = [design_matrices[i] for i in train_]\n",
    "        \n",
    "        cv2 = 0\n",
    "        logo2 = LeaveOneOut() # leave on run out !\n",
    "        for train, valid in logo2.split(fmri_data_train_):\n",
    "            fmri_data_train = [fmri_data_train_[i] for i in train] # fmri_runs liste 2D colonne = voxels et chaque row = un t_i\n",
    "            predictors_train = [predictors_train_[i] for i in train]\n",
    "            dm = np.vstack(predictors_train)\n",
    "            fmri = np.vstack(fmri_data_train)\n",
    "            scores_cv1 = np.zeros((nb_voxels, nb_runs_valid, nb_alphas))\n",
    "            \n",
    "            cv1 = 0\n",
    "            for alpha_tmp in tqdm(alpha_list): # compute the r2 for a given alpha for all the voxel\n",
    "                model.set_params(alpha=alpha_tmp)\n",
    "                model_fitted = model.fit(dm,fmri)\n",
    "                r2 = get_r2_score(model_fitted, fmri_data_train_[valid[0]], predictors_train_[valid[0]])\n",
    "                scores_cv1[:, cv2, cv1] = r2\n",
    "                cv1 += 1\n",
    "            #best_alphas_indexes = np.argmax(scores_cv1, axis=1)\n",
    "            cv2 += 1\n",
    "        best_alphas_indexes = np.argmax(np.mean(scores_cv1, axis=1), axis=1)\n",
    "        alphas_cv2[cv3, :] = np.array([alpha_list[i] for i in best_alphas_indexes])\n",
    "        fmri2 = np.vstack(fmri_data_train_)\n",
    "        dm2 = np.vstack(predictors_train_)\n",
    "        for voxel in tqdm(range(nb_voxels)): # loop through the voxels and fit the model with the best alpha for this voxel\n",
    "            y = fmri2[:,voxel].reshape((fmri2.shape[0],1))\n",
    "            model.set_params(alpha=alphas_cv2[cv3, voxel])\n",
    "            model_fitted = model.fit(dm2, y)\n",
    "            scores_cv2[cv3, voxel] = get_r2_score(model_fitted, \n",
    "                                            fmri_runs[test[0]][:,voxel].reshape((fmri_runs[test[0]].shape[0],1)), \n",
    "                                            design_matrices[test[0]])\n",
    "            # log the results\n",
    "            log(subject, voxel=voxel, alpha=alphas_cv2[cv3, voxel], r2=scores_cv2[cv3, voxel])\n",
    "        cv3 += 1\n",
    "        \n",
    "    return np.mean(alphas_cv2, axis=0), np.mean(scores_cv2, axis=0) # compute mean vertically (in time)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = get_data(language, input_data_type, model=model_name, source='fMRI')\n",
    "fmri_runs = {subject: get_data(language, data_type=source, subject=subject) for subject in subjects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parent_folder = get_output_parent_folder(source, output_data_type, language, model_name)\n",
    "check_folder(output_parent_folder) # check if the output_parent_folder exists and create it if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/ridge-indiv/english/lstm_wikikristina_embedding-size_200_nhid_100_nlayers_3_dropout_01'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parent_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_design_matrices(path):\n",
    "    # Read design matrice csv file and add a column with only 1\n",
    "    dm = pd.read_csv(path, header=0)\n",
    "    # add the constant\n",
    "    # const = np.ones((dm.shape[0], 1))\n",
    "    # dm = np.hstack((dm, const))\n",
    "    return dm \n",
    "\n",
    "\n",
    "def compute_global_masker(files): # [[path, path2], [path3, path4]]\n",
    "    # return a MultiNiftiMasker object\n",
    "\n",
    "    #spm_dir = '/neurospin/unicog/protocols/IRMf/Meyniel_MarkovGuess_2014'\n",
    "    #mask = join(spm_dir, 'spm12/tpm/mask_ICV.nii')\n",
    "    #global_mask = math_img('img>0', img=mask)\n",
    "    #masker = MultiNiftiMasker(mask_img=global_mask)\n",
    "    #masker.fit()\n",
    "\n",
    "    masks = [compute_epi_mask(f) for f in files]\n",
    "    global_mask = math_img('img>0.5', img=mean_img(masks)) # take the average mask and threshold at 0.5\n",
    "    masker = MultiNiftiMasker(global_mask, detrend=params.pref.detrend, standardize=params.pref.standardize) # return a object that transforms a 4D barin into a 2D matrix of voxel-time and can do the reverse action\n",
    "    masker.fit()\n",
    "    return masker\n",
    "\n",
    "\n",
    "matrices = [transform_design_matrices(run) for run in dm] # list of design matrices (dataframes) where we added a constant column equal to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_global_masker(files): # [[path, path2], [path3, path4]]\n",
    "    # return a MultiNiftiMasker object\n",
    "\n",
    "    #spm_dir = '/neurospin/unicog/protocols/IRMf/Meyniel_MarkovGuess_2014'\n",
    "    #mask = join(spm_dir, 'spm12/tpm/mask_ICV.nii')\n",
    "    #global_mask = math_img('img>0', img=mask)\n",
    "    #masker = MultiNiftiMasker(mask_img=global_mask)\n",
    "    #masker.fit()\n",
    "\n",
    "    masks = [compute_epi_mask(f) for f in files]\n",
    "    global_mask = math_img('img>0.5', img=mean_img(masks)) # take the average mask and threshold at 0.5\n",
    "    masker = MultiNiftiMasker(global_mask, detrend=params.pref.detrend, standardize=params.pref.standardize) # return a object that transforms a 4D barin into a 2D matrix of voxel-time and can do the reverse action\n",
    "    masker.fit()\n",
    "    return masker\n",
    "\n",
    "\n",
    "masker = compute_global_masker(list(fmri_runs.values()))  # return a MultiNiftiMasker object ... computation is sloow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fMRI data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/volatile/anaconda3/lib/python3.7/site-packages/nilearn/signal.py:58: RuntimeWarning: invalid value encountered in sqrt\n",
      "  std = np.sqrt((signals ** 2).sum(axis=0))\n"
     ]
    }
   ],
   "source": [
    "fmri = [masker.transform(f) for f in fmri_runs['sub-057']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.3461719e-09 -7.3977398e-09  7.1863755e-09 ... -2.4306859e-08\n",
      " -3.3818237e-09  9.3000159e-09]\n",
      "[1.0000001  0.99999934 1.         ... 1.0000004  0.9999988  0.9999997 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(fmri[0], axis=0))\n",
    "print(np.var(fmri[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.466866e-07"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(fmri[0], axis=0).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## design matrices analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007430509538868077"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.var(matrices[0], axis=0), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hrf0       0.011004\n",
       "hrf1       0.013050\n",
       "hrf2       0.012366\n",
       "hrf3       0.011697\n",
       "hrf4       0.009709\n",
       "hrf5       0.012320\n",
       "hrf6       0.011202\n",
       "hrf7       0.012861\n",
       "hrf8       0.008130\n",
       "hrf9       0.016026\n",
       "hrf10      0.014013\n",
       "hrf11      0.019131\n",
       "hrf12      0.012619\n",
       "hrf13      0.017643\n",
       "hrf14      0.016408\n",
       "hrf15      0.015829\n",
       "hrf16      0.011679\n",
       "hrf17      0.014610\n",
       "hrf18      0.012226\n",
       "hrf19      0.011136\n",
       "hrf20      0.010450\n",
       "hrf21      0.008489\n",
       "hrf22      0.013828\n",
       "hrf23      0.016744\n",
       "hrf24      0.017308\n",
       "hrf25      0.013293\n",
       "hrf26      0.010891\n",
       "hrf27      0.008866\n",
       "hrf28      0.010044\n",
       "hrf29      0.014817\n",
       "             ...   \n",
       "hrf1771    0.001743\n",
       "hrf1772    0.003098\n",
       "hrf1773    0.005431\n",
       "hrf1774    0.003919\n",
       "hrf1775    0.009133\n",
       "hrf1776    0.003599\n",
       "hrf1777    0.003712\n",
       "hrf1778    0.003429\n",
       "hrf1779    0.004771\n",
       "hrf1780    0.005945\n",
       "hrf1781    0.004741\n",
       "hrf1782    0.004597\n",
       "hrf1783    0.006184\n",
       "hrf1784    0.005405\n",
       "hrf1785    0.004700\n",
       "hrf1786    0.002640\n",
       "hrf1787    0.002110\n",
       "hrf1788    0.004695\n",
       "hrf1789    0.002827\n",
       "hrf1790    0.003093\n",
       "hrf1791    0.006139\n",
       "hrf1792    0.003080\n",
       "hrf1793    0.005709\n",
       "hrf1794    0.002412\n",
       "hrf1795    0.004624\n",
       "hrf1796    0.004472\n",
       "hrf1797    0.004235\n",
       "hrf1798    0.006265\n",
       "hrf1799    0.005620\n",
       "hrf1800    0.914013\n",
       "Length: 1801, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(matrices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/volatile/anaconda3/lib/python3.7/site-packages/nilearn/signal.py:58: RuntimeWarning: invalid value encountered in sqrt\n",
      "  std = np.sqrt((signals ** 2).sum(axis=0))\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting model...\n",
      "[[ 0.09249381  1.03316691 -0.96822362 ... -4.83329658  0.\n",
      "   1.        ]\n",
      " [ 0.08029354  0.99437744 -0.92808402 ... -4.78497582  0.\n",
      "   1.        ]\n",
      " [-0.1764666   0.27685935 -0.11686628 ... -3.95763289  0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.78316756  0.3423067  -0.75517662 ...  0.63125785  0.\n",
      "   1.        ]\n",
      " [-1.11991281 -0.07033856 -0.8811043  ... -0.6971583   0.\n",
      "   1.        ]\n",
      " [-0.97049448 -0.07851874 -0.9385073  ... -2.89512589  0.\n",
      "   1.        ]]\n",
      "Model fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:07,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "None\n",
      "\n",
      "Fitting model...\n",
      "[[ 0.51552478  0.93670204 -0.97307604 ... -4.89541536  0.\n",
      "   1.        ]\n",
      " [ 0.56233511  0.97812661 -1.00221575 ... -4.83138309  0.\n",
      "   1.        ]\n",
      " [ 0.97564125  1.06628989 -0.87785006 ... -3.39458131  0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.78316756  0.3423067  -0.75517662 ...  0.63125785  0.\n",
      "   1.        ]\n",
      " [-1.11991281 -0.07033856 -0.8811043  ... -0.6971583   0.\n",
      "   1.        ]\n",
      " [-0.97049448 -0.07851874 -0.9385073  ... -2.89512589  0.\n",
      "   1.        ]]\n",
      "Model fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:15,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "Fitting model...\n",
      "[[ 0.51552478  0.93670204 -0.97307604 ... -4.89541536  0.\n",
      "   1.        ]\n",
      " [ 0.56233511  0.97812661 -1.00221575 ... -4.83138309  0.\n",
      "   1.        ]\n",
      " [ 0.97564125  1.06628989 -0.87785006 ... -3.39458131  0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.78316756  0.3423067  -0.75517662 ...  0.63125785  0.\n",
      "   1.        ]\n",
      " [-1.11991281 -0.07033856 -0.8811043  ... -0.6971583   0.\n",
      "   1.        ]\n",
      " [-0.97049448 -0.07851874 -0.9385073  ... -2.89512589  0.\n",
      "   1.        ]]\n",
      "Model fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:25,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "Fitting model...\n",
      "[[ 0.51552478  0.93670204 -0.97307604 ... -4.89541536  0.\n",
      "   1.        ]\n",
      " [ 0.56233511  0.97812661 -1.00221575 ... -4.83138309  0.\n",
      "   1.        ]\n",
      " [ 0.97564125  1.06628989 -0.87785006 ... -3.39458131  0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.78316756  0.3423067  -0.75517662 ...  0.63125785  0.\n",
      "   1.        ]\n",
      " [-1.11991281 -0.07033856 -0.8811043  ... -0.6971583   0.\n",
      "   1.        ]\n",
      " [-0.97049448 -0.07851874 -0.9385073  ... -2.89512589  0.\n",
      "   1.        ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-42288435d4d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdo_single_subject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sub-057'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmri_runs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sub-057'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_parent_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-7c3a7a69af5b>\u001b[0m in \u001b[0;36mdo_single_subject\u001b[0;34m(subject, fmri_filenames, design_matrices, masker, output_parent_folder, model, voxel_wised, alpha_list)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mcreate_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'alphas'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_parent_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# alphas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mr2_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhole_brain_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmri_runs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesign_matrices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mcreate_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r2_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_parent_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# r2 test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-7c3a7a69af5b>\u001b[0m in \u001b[0;36mwhole_brain_analysis\u001b[0;34m(model, fmri_runs, design_matrices, subject)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mmodel_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmri_data_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fitted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath2derivatives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fMRI/glm-indiv/english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'('\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'{}.sav'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model fitted.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "do_single_subject('sub-057', fmri_runs['sub-057'], matrices, masker, output_parent_folder, Ridge(alpha=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " model0 = pickle.load(open('../derivatives/fMRI/glm-indiv/english/Ridge0.sav', 'rb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def score(model, y_true, y2predict, r2_min=0., r2_max=0.99):\n",
    "    # return the R2_score for each voxel (=list)\n",
    "    r2 = r2_score(y_true,\n",
    "                    model.predict(y2predict),\n",
    "                    multioutput='raw_values')\n",
    "    # remove values with are too low and values too good to be true (e.g. voxels without variation)\n",
    "    return r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.93509985 -0.64446331 -0.88661538 ... -0.63107091 -0.55321624\n",
      " -0.42332446]\n",
      "[0.81009184 0.78868673 0.66975513 ... 0.69780812 0.5355706  0.67318141]\n",
      "[0.76560918 0.75443431 0.72637514 ... 0.83806554 0.47992103 0.65503762]\n",
      "[0.85089121 0.69745401 0.71986867 ... 0.82612955 0.79959495 0.80246686]\n",
      "[0.86092896 0.84941064 0.8131006  ... 0.84129548 0.86621197 0.85574448]\n",
      "[0.77404616 0.78099343 0.69418221 ... 0.6157649  0.64726411 0.68747466]\n",
      "[0.78109189 0.76884263 0.67936397 ... 0.69429171 0.45493624 0.40440284]\n",
      "[0.79776277 0.73603875 0.62851883 ... 0.69931141 0.66010711 0.64442444]\n",
      "[0.77092608 0.76708132 0.66163465 ... 0.74660716 0.66546268 0.75174625]\n"
     ]
    }
   ],
   "source": [
    "for index in range(9): print(score(model0, fmri[index], matrices[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.93509985, -0.64446331, -0.88661538, ..., -0.63107091,\n",
       "       -0.55321624, -0.42332446])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(fmri[0], (np.dot(matrices[0], model0.coef_.T) + model0.intercept_), multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4fc8d335d84b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfmri_runs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def show(data): \n",
    "    plt.figure(figsize=(7,5)) \n",
    "    plt.plot(data) \n",
    "    plt.show() \n",
    "\n",
    "show((np.dot(matrices[0], model0.coef_.T) + model0.intercept_ - fmri_runs[0])[:, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command line: \n",
    "\n",
    "python ridge-indiv.py --language english --model_name lstm_wikikristina_embedding-size_200_nhid_100_nlayers_3_dropout_01 --parallel  --subjects sub-057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
